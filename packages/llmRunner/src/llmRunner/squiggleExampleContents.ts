// This file is auto-generated. Do not edit manually.
export const squiggleExampleContents = new Map([
  [
    "hub:ozziegooen/virus-model",
    'import "hub:ozziegooen/wells-riley-model" as wellsRileyModel\nimport "hub:ozziegooen/room-model" as roomModel\n/*\nDemo for estimating the damage caused by virus\n\nOne issue is that we might need to simulate the infected people. This means that there will only be a small probability that each person will be impacted. If we simulate this for each person, this will be limited.\n\nNote that one check to these results, is that they should roughly imply an equilibrium - the expected new cases should roughly match the suspected time average of new cases. \n\n//For eventual calculators, we want people to vary:\n- Prevalence of disease. Can be separate for both, or similar. 2 vs. 10 vs. 20. per 100k.\n- Maybe the list of rooms, as a text box.\n- Maybe population of people. "City block", "Small Town", "Medium Town" -> Composition.\n\n- Timeline - A test case for demonstrating what calculators could be built for team and such.\n- If it can be done by November 6, that would be good. \n\n*/\n\nquantumMeasures = { flu: 15 to 500, covid: 15 to 50 }\n\n// BY PERSON ---------------\ngetGender = mx(0, 1)\ngetAge = 15 to 70\n\nperson() = {\n  gender: sample(getGender) > 0.5 ? "male" : "female",\n  age: sample(getAge),\n  lungCapacity: 0.4,\n}\n\npersonCalculator = Calculator(person, { autorun: false })\n\n// POPULATIONS ---------------\n\npopulationInfectionPercentages = { flu: 0.001, covid: 0.001 }\n\n// CITY ROOM LAYOUTS ---------------\n\nmaker(numberOfRooms, populationInfectionPercentages, airChange) = {\n  rooms = List(\n    numberOfRooms,\n    {|| roomModel.make(populationInfectionPercentages)}\n  )\n  potentiallyInfectiousRooms = rooms\n    -> List.filter(\n      {|room| room.vulnerablePersonCount > 0}\n    )\n    -> map(\n      {\n        |room|\n        people = List(room.vulnerablePersonCount, person)\n          -> map(\n            {|person| Dict.set(person, "timeSpent", sample(room.timeSpent))}\n          )\n          -> map(\n            {\n              |person|\n              diseaseStats(diseaseName, changeInAir) = wellsRileyModel.model(\n                room.infectedPersonCounts[diseaseName],\n                person.timeSpent,\n                quantumMeasures[diseaseName],\n                person.lungCapacity,\n                room.averageAirChangePerHour * changeInAir,\n                room.volume\n              )\n              diseases = ["flu", "covid"]\n              person\n                -> Dict.set(\n                  "pDiseases",\n                  List.map(\n                    diseases,\n                    {\n                      |d|\n                      [\n                        d,\n                        {\n                          regular: diseaseStats(d, 1),\n                          withFilter: diseaseStats(d, airChange),\n                        },\n                      ]\n                    }\n                  )\n                    -> Dict.fromList\n                )\n            }\n          )\n        Dict.set(room, "people", people)\n      }\n    )\n\n  { rooms, potentiallyInfectiousRooms }\n}\n\ngetAggregate(roomInfo) = {\n  rooms = roomInfo.rooms\n  potentiallyInfectiousRooms = roomInfo.potentiallyInfectiousRooms\n\n  personAggregate(population, fn) = population -> map({|r| map(r.people, fn)})\n    -> List.flatten\n    -> sum\n\n  diseaseAggregates(population, diseaseName) = {\n    withoutFiltration = personAggregate(\n      potentiallyInfectiousRooms,\n      {|p| p.pDiseases[diseaseName]["regular"]}\n    )\n    withFiltration = personAggregate(\n      potentiallyInfectiousRooms,\n      {|p| p.pDiseases[diseaseName]["withFilter"]}\n    )\n    {\n      withoutFiltration,\n      withFiltration,\n      filtrationBenefit: withoutFiltration - withFiltration,\n    }\n  }\n\n  timeTotalInfectious = personAggregate(\n    potentiallyInfectiousRooms,\n    {|p| p.timeSpent}\n  )\n\n  explanations = "\n  **potentiallyInfectiousRooms**:  \nA list of all the rooms with at least one infectious person. We only do analysis on these rooms, as the others have no chance of infections.  \n\n  **riskyInstances**:  \n  How many situations were there where a person was in a room with an infectious person?  \n  \n  **diseaseTotals**:  \n  On average, how many people would we expect to become infected? Without extra filtration, with extra filtration, and the difference of those two (how many cases did filtration prevent, in expectation?)\n  \n  **rooms**:  \n  The full list of rooms. These don\'t have as much information in them as with the infectedRooms, but still have some.\n  "\n  {\n    explanations,\n    potentiallyInfectiousRooms,\n    riskyInstances: potentiallyInfectiousRooms\n      -> map(\n        {|r| r.vulnerablePersonCount}\n      )\n      -> sum,\n    diseaseTotals: {\n      flu: diseaseAggregates(potentiallyInfectiousRooms, "flu"),\n      covid: diseaseAggregates(potentiallyInfectiousRooms, "covid"),\n    },\n    //timeTotalInfectious: "" + timeTotalInfectious + " Hours",\n    rooms,\n  }\n}\n\nexport chanceCalculator = Calculator(\n  {\n    |rooms, flu, covid, airChange|\n    maker(rooms, { flu, covid }, airChange) -> getAggregate\n  },\n  {\n    title: "Expected Flu and COVID cases for N number of Room Sessions",\n    description: "Throughout the day, people will spend time in different rooms. In this calculator, we:\n1. Generate *N* rooms, each with a distribution of time spent in them, volume, number of people in them, etc.\n2. We sample them to determine which have infected people in them.\n3. For the rooms with infected people, we randomly generate people and durations that each stayed in the room.\n4. After steps (1-3), we use the *Wells Riley Model* to estimate the probability that that person, in that period, became sick.\n5. We calculate the total probabilities of people getting flu and COVID, for the entire set of periods and rooms. This gives a rough idea of how many people will get infected during this time.",\n    autorun: false,\n    inputs: [\n      Input.text(\n        {\n          name: "Number of Rooms",\n          description: "For each, we\'ll take one snapshot of N people who might have been in the room at a certain point. We\'d then figure out how long each was in the room for. Note: This must be a number, it can\'t be a distribution.",\n          default: 100,\n        }\n      ),\n      Input.text(\n        {\n          name: "Population with Flu",\n          description: "What proportion of the population has the flu? 0.01 means 1%. You can type ratios, like \'1/10k\'. Note: This can be a distribution, like, \'0.02 to 0.04\'.",\n          default: 0.02,\n        }\n      ),\n      Input.text({ name: "Population with COVID", default: 0.03 }),\n      Input.text(\n        {\n          name: "Air Change with Filter",\n          description: "How much does the filter effectively increase the air change per hour? 1.5 means a 50% increase.",\n          default: "1.1 to 1.3",\n        }\n      ),\n    ],\n  }\n)\nchanceCalculator',
  ],
  [
    "hub:ozziegooen/meeting-cost-calculator",
    'wordsPerMinute = 110 to 150\n\n// cost per person\n// cost per event\n// cost per person per word\n// cost per event per word\n\nevent(numberOfPeople, costPerHour, hours, hoursofPrep) = numberOfPeople *\n  costPerHour *\n  (hours + hoursofPrep)\n\nformatted(numberOfPeople, costPerHour, hours, hoursofPrep, wpm) = {\n  totalCost = event(numberOfPeople, costPerHour, hours, hoursofPrep)\n  data = [\n    {\n      name: "Full Event",\n      cost: totalCost,\n      costPerWord: totalCost / (wpm * hours * 60),\n    },\n    {\n      name: "Per Person",\n      cost: totalCost / numberOfPeople,\n      costPerWord: totalCost / (wpm * hours * 60) / numberOfPeople,\n    },\n  ]\n  table = data\n    -> Table(\n      {\n        columns: [\n          { name: "Name", fn: {|d| d.name} },\n          { name: "Cost (Total)", fn: {|d| d.cost} },\n          { name: "Cost per Word", fn: {|d| d.costPerWord} },\n        ],\n      }\n    )\n  bar = { totalCost: totalCost, wordsSpoken: wpm * hours * 60, table }\n  bar\n}\n\na = formatted\n  -> Calculator(\n    {\n      description: "## Cost of Time Spent at Event\n*Note: This calulation assumes that uncertainty in value of time is independent of uncertainty in the hours spent. I guess this might be a bit negatively correlated, so keep this in mind.*",\n      inputs: [\n        Input.text({ name: "Number of Attendees", default: "5" }),\n        Input.text(\n          {\n            name: "Counterfactual Value of Time (per hour)",\n            default: "30 to 70",\n            description: "Use the mean, not median.",\n          }\n        ),\n        Input.text(\n          {\n            name: "Hours of event",\n            default: "1 to 5",\n            description: "Again, use the mean.",\n          }\n        ),\n        Input.text(\n          {\n            name: "Extra hours, for preparation, travel, and distractions",\n            default: "0.2 to 1.5",\n            description: "How much time did the mean attendee spend getting ready, traveling, and being distracted (interrupting other work), for this event?",\n          }\n        ),\n        Input.text(\n          {\n            name: "Words per Minute",\n            default: "120 to 150",\n            description: "Again, use the mean.",\n          }\n        ),\n      ],\n    }\n  )\na',
  ],
  [
    "hub:ozziegooen/laptop-battery-cost",
    '@name("Charging Efficiency % (A Constant)")\nchargingEfficiency = 0.7 to 0.9\n\n@name("Fn: Cost to Charge Battery Once")\ncostToCharge(batteryCapacity, electricityRate, chargingEfficiency) = {\n  loadInkWh = batteryCapacity / 1000\n  chargeCost = loadInkWh * electricityRate / chargingEfficiency\n  chargeCost\n}\n\n@name("Fn: Calculate Total Costs")\ncalcCosts(\n  batteryCapacity,\n  electricityRate,\n  batteryCycles,\n  batteryCost,\n  hoursOfUsePerCycle\n) = {\n  electricityCostPerCycle = costToCharge(\n    batteryCapacity,\n    electricityRate,\n    chargingEfficiency\n  )\n  batteryCostPerCycle = batteryCost / batteryCycles\n\n  @name("Costs per Full Battery Cycle")\n  perCycleCosts = Plot.dists(\n    {\n      dists: [\n        { name: "Electricity Cost", value: electricityCostPerCycle },\n        { name: "Battery Depreciation", value: batteryCostPerCycle },\n      ],\n      xScale: Scale.linear({ tickFormat: "$.2f" }),\n    }\n  )\n\n  @name("Costs per Hour of Use")\n  perHourCosts = Plot.dists(\n    {\n      dists: [\n        {\n          name: "Electricity Cost",\n          value: electricityCostPerCycle / hoursOfUsePerCycle,\n        },\n        {\n          name: "Battery Depreciation",\n          value: batteryCostPerCycle / hoursOfUsePerCycle,\n        },\n      ],\n      xScale: Scale.linear({ tickFormat: "$.2f" }),\n    }\n  )\n\n  { perCycleCosts, perHourCosts }\n}\n\n@name("Calculator")\nexport calculator = Calculator(\n  calcCosts,\n  {\n    title: "Laptop Usage Costs: Electricity & Battery",\n    description: "This calculator estimates the combined costs of electricity consumption and battery depreciation for laptop use. It assumes the laptop is running on battery power.\n\nCosts are provided per **full battery cycle** and per **hour of use**.",\n    inputs: [\n      Input.text(\n        {\n          name: "Battery Capacity (Watt-Hours)",\n          default: "60",\n          description: "E.g., A 14-inch M1 MacBook Pro has ~60 Wh battery.",\n        }\n      ),\n      Input.text(\n        {\n          name: "Electricity Rate ($ per kWh)",\n          description: "E.g., In California, this was ~$0.20 in 2022.",\n          default: "0.2 to 0.3",\n        }\n      ),\n      Input.text(\n        {\n          name: "Battery Lifespan (Cycles)",\n          description: "Number of full charge cycles before battery replacement is needed.",\n          default: "1000 to 1500",\n        }\n      ),\n      Input.text(\n        {\n          name: "Battery Replacement Cost ($)",\n          description: "Include both monetary cost and inconvenience factor.",\n          default: "100 to 200",\n        }\n      ),\n      Input.text(\n        {\n          name: "Battery Life per Charge (Hours)",\n          description: "Typical usage time on a single charge.",\n          default: "3 to 5",\n        }\n      ),\n    ],\n  }\n)\n',
  ],
  [
    "hub:ozziegooen/shapley-values",
    '/*\nSimple Shapley Value Calculator\n\nSome math from GPT-4 plus this blog post:\nhttps://www.aidancooper.co.uk/how-shapley-values-work/\n\nInspiration from Nuno Sempere\'s Shapley Value Calculator\nhttps://shapleyvalue.com/\n\nExported Functions:\n\nshapleyCalculation2Players(vEmpty, v1, v2, v1and2)\nshapleyCalculation3Players(vEmpty, v1, v2, v3, ...) // See definition\nshapleyCalculation4Players(vEmpty, v1, v2, v3, ...) // See definition\n\n\nCode and Calculators:\n\nThe code is very explicit, because this was simpler to write. Doing a generic version in Squiggle was messier, and didn\'t seem very critical. If you really want to use functions with over 4 players on Squiggle, let me know.\n\nWe only export one super-calculator, for simplicity. If you want me to export the specific calculators with preset players, please message me.\n*/\n\ncoalitions2Players = ["()", "(1)", "(2)", "(1,2)"]\n\n// Function to calculate Shapley values\nexport shapleyCalculation2Players(\n  v_0,\n  v_1,\n  v_2,\n  v_1_2 // Calculate marginal contributions\n) = // Average marginal contributions for each player\n{\n  marginal_1 = v_1 - v_0\n  marginal_2 = v_2 - v_0\n  marginal_1_2_to_1 = v_1_2 - v_2\n  marginal_1_2_to_2 = v_1_2 - v_1\n\n  shapley_1 = (marginal_1 + marginal_1_2_to_1) / 2\n  shapley_2 = (marginal_2 + marginal_1_2_to_2) / 2\n\n  { player1: shapley_1, player2: shapley_2 }\n}\n\nb2 = Calculator(\n  shapleyCalculation2Players,\n  {\n    title: "Shapley Value with 2 Players",\n    inputs: coalitions2Players\n      -> List.map(\n        {|player, i| Input.text({ name: "Value of " + player, default: i })}\n      ),\n  }\n)\n\ncoalitions3Players = [\n  "()",\n  "(1)",\n  "(2)",\n  "(3)",\n  "(1,2)",\n  "(1,3)",\n  "(2,3)",\n  "(1,2,3)",\n]\n\n// Function to calculate Shapley values\nexport shapleyCalculation3Players(\n  v_0,\n  v_1,\n  v_2,\n  v_3,\n  v_1_2,\n  v_1_3,\n  v_2_3,\n  v_1_2_3 // Calculate marginal contributions\n) = // Average marginal contributions for each player\n{\n  marginal_1 = v_1 - v_0\n  marginal_2 = v_2 - v_0\n  marginal_3 = v_3 - v_0\n  marginal_1_2_to_1 = v_1_2 - v_2\n  marginal_1_2_to_2 = v_1_2 - v_1\n  marginal_1_3_to_1 = v_1_3 - v_3\n  marginal_1_3_to_3 = v_1_3 - v_1\n  marginal_2_3_to_2 = v_2_3 - v_3\n  marginal_2_3_to_3 = v_2_3 - v_2\n  marginal_1_2_3_to_1 = v_1_2_3 - v_2_3\n  marginal_1_2_3_to_2 = v_1_2_3 - v_1_3\n  marginal_1_2_3_to_3 = v_1_2_3 - v_1_2\n\n  shapley_1 = (marginal_1 + marginal_1_2_3_to_1) / 3 +\n    (marginal_1_2_to_1 + marginal_1_3_to_1) / 6\n  shapley_2 = (marginal_2 + marginal_1_2_3_to_2) / 3 +\n    (marginal_1_2_to_2 + marginal_2_3_to_2) / 6\n  shapley_3 = (marginal_3 + marginal_1_2_3_to_3) / 3 +\n    (marginal_2_3_to_3 + marginal_1_3_to_3) / 6\n\n  { player1: shapley_1, player2: shapley_2, player3: shapley_3 }\n}\n\nb3 = Calculator(\n  shapleyCalculation3Players,\n  {\n    title: "Shapley Value with 3 Players",\n    inputs: coalitions3Players\n      -> List.map(\n        {|player, i| Input.text({ name: "Value of " + player, default: i })}\n      ),\n  }\n)\n\ncoalitions4Players = [\n  "()",\n  "(1)",\n  "(2)",\n  "(3)",\n  "(4)",\n  "(1,2)",\n  "(1,3)",\n  "(1,4)",\n  "(2,3)",\n  "(2,4)",\n  "(3,4)",\n  "(1,2,3)",\n  "(1,2,4)",\n  "(1,3,4)",\n  "(2,3,4)",\n  "(1,2,3,4)",\n]\n\n// Function to calculate Shapley values\nexport shapleyCalculation4Players(\n  v_0,\n  v_1,\n  v_2,\n  v_3,\n  v_4,\n  v_1_2,\n  v_1_3,\n  v_1_4,\n  v_2_3,\n  v_2_4,\n  v_3_4,\n  v_1_2_3,\n  v_1_2_4,\n  v_1_3_4,\n  v_2_3_4,\n  v_1_2_3_4\n) = {\n  marginal_1 = v_1 - v_0\n  marginal_2 = v_2 - v_0\n  marginal_3 = v_3 - v_0\n  marginal_4 = v_4 - v_0\n  marginal_1_2_to_1 = v_1_2 - v_2\n  marginal_1_2_to_2 = v_1_2 - v_1\n  marginal_1_3_to_1 = v_1_3 - v_3\n  marginal_1_3_to_3 = v_1_3 - v_1\n  marginal_1_4_to_1 = v_1_4 - v_4\n  marginal_1_4_to_4 = v_1_4 - v_1\n  marginal_2_3_to_2 = v_2_3 - v_3\n  marginal_2_3_to_3 = v_2_3 - v_2\n  marginal_2_4_to_2 = v_2_4 - v_4\n  marginal_2_4_to_4 = v_2_4 - v_2\n  marginal_3_4_to_3 = v_3_4 - v_4\n  marginal_3_4_to_4 = v_3_4 - v_3\n  marginal_1_2_3_to_1 = v_1_2_3 - v_2_3\n  marginal_1_2_3_to_2 = v_1_2_3 - v_1_3\n  marginal_1_2_3_to_3 = v_1_2_3 - v_1_2\n  marginal_1_2_4_to_1 = v_1_2_4 - v_2_4\n  marginal_1_2_4_to_2 = v_1_2_4 - v_1_4\n  marginal_1_2_4_to_4 = v_1_2_4 - v_1_2\n  marginal_1_3_4_to_1 = v_1_3_4 - v_3_4\n  marginal_1_3_4_to_3 = v_1_3_4 - v_1_4\n  marginal_1_3_4_to_4 = v_1_3_4 - v_1_3\n  marginal_2_3_4_to_2 = v_2_3_4 - v_3_4\n  marginal_2_3_4_to_3 = v_2_3_4 - v_2_4\n  marginal_2_3_4_to_4 = v_2_3_4 - v_2_3\n  marginal_1_2_3_4_to_1 = v_1_2_3_4 - v_2_3_4\n  marginal_1_2_3_4_to_2 = v_1_2_3_4 - v_1_3_4\n  marginal_1_2_3_4_to_3 = v_1_2_3_4 - v_1_2_4\n  marginal_1_2_3_4_to_4 = v_1_2_3_4 - v_1_2_3\n\n  shapley_1 = (marginal_1 + marginal_1_2_3_4_to_1) / 4 +\n    (marginal_1_2_to_1 + marginal_1_3_to_1 + marginal_1_4_to_1 +\n      marginal_1_2_3_to_1 +\n      marginal_1_2_4_to_1 +\n      marginal_1_3_4_to_1) /\n      12\n  shapley_2 = (marginal_2 + marginal_1_2_3_4_to_2) / 4 +\n    (marginal_1_2_to_2 + marginal_2_3_to_2 + marginal_2_4_to_2 +\n      marginal_1_2_3_to_2 +\n      marginal_1_2_4_to_2 +\n      marginal_2_3_4_to_2) /\n      12\n  shapley_3 = (marginal_3 + marginal_1_2_3_4_to_3) / 4 +\n    (marginal_1_3_to_3 + marginal_2_3_to_3 + marginal_3_4_to_3 +\n      marginal_1_2_3_to_3 +\n      marginal_1_3_4_to_3 +\n      marginal_2_3_4_to_3) /\n      12\n  shapley_4 = (marginal_4 + marginal_1_2_3_4_to_4) / 4 +\n    (marginal_1_4_to_4 + marginal_2_4_to_4 + marginal_3_4_to_4 +\n      marginal_1_2_4_to_4 +\n      marginal_1_3_4_to_4 +\n      marginal_2_3_4_to_4) /\n      12\n\n  {\n    player1: shapley_1,\n    player2: shapley_2,\n    player3: shapley_3,\n    player4: shapley_4,\n  }\n}\n\nb4 = Calculator(\n  shapleyCalculation4Players,\n  {\n    title: "Shapley Value with 4 Players",\n    inputs: coalitions4Players\n      -> List.map(\n        {|player, i| Input.text({ name: "Value of " + player, default: i })}\n      ),\n  }\n)\n\nexport calc = Calculator(\n  {|e| if e == "2" then b2 else if e == "3" then b3 else b4},\n  {\n    title: "Shapley Calculator for 2-4 Players",\n    description: "Calculates the [Shapley Value](https://en.wikipedia.org/wiki/Shapley_value) for different players. \n### Naming convention:\n- () => No players\n- (1) => Just the first player\n- (1,2) => The value of just the combination of players 1 and 2.\n\n### Sources\nInspiration from [Nuno Sempere\'s Shapley Value Calculator](https://shapleyvalue.com/).    \n\nSome math from this blog post:\n[https://www.aidancooper.co.uk/how-shapley-values-work/](https://www.aidancooper.co.uk/how-shapley-values-work/).\n\n",\n    inputs: [\n      Input.select(\n        { name: "Number of Players", options: ["2", "3", "4"], default: "2" }\n      ),\n    ],\n  }\n)\n',
  ],
  [
    "hub:ozziegooen/AI-safety-company-factors",
    '/*\nExperimental, in-progress model of AI safety compute, over time.\n*/\n\nstartYear = 2023\nendYear = 2080\nyearRange = [startYear, endYear]\n\ntransformative_ai_timelines(t: yearRange) = {\n  dist = mx(logistic(30, 10), logistic(30, 30), [0.9, 0.4]) -> truncateLeft(0)\n  chance_will_happen_at_all = 0.8\n  cdf(dist, t - startYear) * chance_will_happen_at_all\n}\n\ncompanies = [\n  { name: "OpenAI", safetyFactor: 1.1, shortFactor: 0.3, longFactor: 0.08 },\n  { name: "Anthropic", safetyFactor: 2, shortFactor: 0.2, longFactor: 0.008 },\n  {\n    name: "Alphabet (Not Deepmind)",\n    safetyFactor: 0.3,\n    shortFactor: 0.1,\n    longFactor: 0.01,\n  },\n  { name: "Deepmind", safetyFactor: 0.9, shortFactor: 0.3, longFactor: 0.08 },\n  { name: "Meta", safetyFactor: 0.4, shortFactor: 0.2, longFactor: 0.1 },\n  {\n    name: "US Government",\n    safetyFactor: 1.5,\n    shortFactor: 0.2,\n    longFactor: 0.25,\n  },\n  {\n    name: "Chinese Government",\n    safetyFactor: 1.3,\n    shortFactor: 0.2,\n    longFactor: 0.2,\n  },\n]\n\n// Starts at 0.3, ends at 0.9, over the t=0 to t=100 range\nlogarithmicCurveOverTime(start, end, t) = {\n  duration = yearRange[1] - yearRange[0]\n  // Use logarithmic interpolation\n  // Use logarithmic interpolation\n  progress = log(1 + t) / log(1 + duration)\n\n  // Apply cubic easing curve\n  // Apply cubic easing curve\n  easedProgress = progress ^ 3\n  start + (end - start) * easedProgress\n\n}\n\ngenericSafetyCurve(t: yearRange) = logarithmicCurveOverTime(\n  0.4,\n  0.8,\n  t - yearRange[0]\n)\n\ntransform_probability(p, transform) = {\n  odds = p / (1 - p)\n  oPrime = odds * transform\n  pPrime = oPrime / (1 + oPrime)\n  pPrime\n}\n\ntransformTest(transform: [0, 2]) = transform_probability(0.8, transform)\ntable = Table(\n  companies,\n  {\n    columns: [\n      { name: "Name", fn: {|e| e.name} },\n      {\n        name: "SafetyChance",\n        fn: {\n          |e|\n          {\n            |t: yearRange|\n            transform_probability(genericSafetyCurve(t), e.safetyFactor)\n          }\n        },\n      },\n    ],\n  }\n)\n',
  ],
  [
    "hub:ozziegooen/ev-agi-to-individuals",
    '/*\nA replication of this Guesstimate code:\nhttps://www.getguesstimate.com/models/10465\n\nThis is a model of the expected value, in QALYs, to a random US citizen, due to Transformative AI.\nI expect that due to TAI, there\'s some probability (around .01% to 10%) that humans alive today will\nhave a long-term positive outcome, meaning that they are sentient and experiencing welfare until roughly\nthe end of the universe.\n\nThere\'s also a chance that there will be an s-risk, and humans now will experience this same time, but\nsuffering. This seems like a smaller chance though.\n\nThis model uses a hyperbolic discount rate. However, on the bottom, we consider a situation where\nthere is a chance of essentially having a discount rate of zero.\n*/\n@hide\ntoLogScale = {|e| Plot.dist(e, { xScale: Scale.log() })}\n@hide\ntoSymScale = {|e| Plot.dist(e, { xScale: Scale.symlog() })}\n@hide\nshowLog(dist) = Tag.showAs(dist, toLogScale)\n@hide\nshowSym(dist) = Tag.showAs(dist, {|e| Plot.dist(e, { xScale: Scale.symlog() })})\n\n@name("Key Variables")\nkeyVariables = {\n  @name("Number of years you will exist in the Universe")\n  @doc("How long will we survive in the universe, in this sitaution?")\n  expectedYearsOfTheUniverse = showLog(100M to 100B)\n\n  @name("Your hyperbolic discount rate")\n  @doc("Quick estimate, feel free to change and see how that effects things.")\n  @showAs(toLogScale)\n  hyperbolicDiscountRate = 0.1% to 10%\n\n  @name("Chance you shouldn\'t discount future QALYs at all")\n  @showAs(toSymScale)\n  chanceDiscountingDoesntMakeSense = 0.1% to 5%\n\n  {\n    expectedYearsOfTheUniverse,\n    hyperbolicDiscountRate,\n    chanceDiscountingDoesntMakeSense,\n  }\n}\n\n@name("AGI Expectation, Post-Transformation")\n@doc(\n  "If we survive post-TAI, each year might be very positive (maybe 1k QALYs/year equivalent) or negative.\nI think that the odds and impact of the negative case are less than that of the positive case."\n)\npostTransformativeAgiExpectations = {\n  positiveChances = showLog(0.0001 to 0.1)\n  positive = {\n    probability: positiveChances,\n    perYearQALYs: showLog(1.2 to 1000),\n  }\n  negative = {\n    probability: showSym(positiveChances * (0.01 to 0.2)),\n    perYearQALYs: showSym(-(0.4 to 1000)),\n  }\n  inExpectation(r) = r.probability * r.perYearQALYs\n  withInExpectation(dict) = Dict.merge(\n    dict,\n    { expectation: inExpectation(dict) -> showSym }\n  )\n  {\n    positive: withInExpectation(positive),\n    negative: withInExpectation(negative),\n    net: {\n      expectation: (inExpectation(positive) + inExpectation(negative))\n        -> showSym,\n    },\n  }\n}\n\n@name("Outcome Table")\n@doc(\n  "Visualize the expected value per year of the negative, positive, and total (negative and positive combined) cases."\n)\noutcomeTable = Table(\n  Dict.toList(postTransformativeAgiExpectations),\n  {\n    columns: [\n      { name: "name", fn: {|e| e[0]} },\n      {\n        name: "probability",\n        fn: {|e| e[0] != "net" ? e[1].probability -> mean : ""},\n      },\n      { name: "EV:mean", fn: {|e| e[1].expectation -> mean} },\n      { name: "EV:p5", fn: {|e| inv(e[1].expectation, 0.05)} },\n      { name: "EV:p95", fn: {|e| inv(e[1].expectation, 0.95)} },\n      {\n        name: "dist",\n        fn: {\n          |e|\n          Plot.dist(\n            e[1].expectation,\n            {\n              xScale: Scale.symlog({ min: -50, max: 500, constant: 0.0000001 }),\n              showSummary: false,\n            }\n          )\n        },\n      },\n    ],\n  }\n)\n\n@name("Discount Rate Functions")\n@doc(\n  "This doesn\'t take into account that AGI might not happen for 10-100 years, in which case, everything should be discounted by that amount extra."\n)\ndiscountRateFn = {\n  rate(discountRate, year) = 1 / (1 + discountRate * year)\n\n  integral(discountRate, years) = {\n    discountInverse = 1 / discountRate\n    discountInverse * (log(discountInverse + years) - log(discountInverse))\n  }\n\n  generatePlots(_rate, maxValue) = {\n    xScale = Scale.symlog({ min: 1, max: maxValue })\n    {\n      rate: Plot.numericFn(\n        {\n          fn: {|t: [0, maxValue]| rate(_rate, t)},\n          xScale: xScale,\n          yScale: Scale.log(),\n        }\n      ),\n      integral: Plot.numericFn(\n        {\n          fn: {|t: [0, maxValue]| integral(_rate, t)},\n          xScale: xScale,\n          yScale: Scale.symlog({ constant: 1 }),\n        }\n      ),\n    }\n  }\n\n  calc = Calculator.make(\n    generatePlots,\n    {\n      inputs: [\n        Input.text({ name: "Discount Rate", default: 0.01 }),\n        Input.text({ name: "Max Year to Show", default: "100B" }),\n      ],\n    }\n  )\n\n  { rate: rate, integral: integral, calc }\n}\n\n@name("Total Expected Value with Hyperbolic Discounting")\n@doc(\n  "This assumes 100M to 100B years, with a hyperbolic Discount rate of 0.001 to 0.1"\n)\ntotalExpectedValueWithDiscountRate = showSym(\n  discountRateFn.integral(\n    keyVariables.hyperbolicDiscountRate,\n    keyVariables.expectedYearsOfTheUniverse\n  ) *\n    postTransformativeAgiExpectations.net.expectation\n)\n\n@name("Total Expected Value with Uncertainty of Discounting")\n@doc(\n  "This assumes a small chance that there should be effectively a 0% discount rate"\n)\ntotalExpectedValueWithDiscountingUncertainty = showSym(\n  totalExpectedValueWithDiscountRate +\n    keyVariables.chanceDiscountingDoesntMakeSense *\n      keyVariables.expectedYearsOfTheUniverse *\n      postTransformativeAgiExpectations.net.expectation\n)\ntotalExpectedValueWithDiscountingUncertainty',
  ],
  [
    "hub:ozziegooen/costs-of-computer-use",
    '@name("Charging efficiency")\n@doc("Power lost when charging")\nchargingEfficiency = 0.7 to 0.9\n\n// Calculate cost\n@hide\ncostToCharge(batteryCapacity, electricityRate, chargingEfficiency) = {\n  loadInkWh = batteryCapacity / 1000\n  costPerkWh = electricityRate\n  chargeCost = loadInkWh * costPerkWh / chargingEfficiency\n  chargeCost\n}\n\n@hide\ndollarFormat = "$.2f"\n\nexport calcCosts(\n  batteryCapacity,\n  electricityRate,\n  batteryCycles,\n  batteryCost,\n  hoursOfUsePerCycle,\n  perUnit\n) = {\n  byHours = perUnit == "Per Hour"\n  unitAdjustment(cost) = perUnit == "Per Hour" ? cost /\n    hoursOfUsePerCycle : cost\n  totalElectricityCostToCharge = costToCharge(\n    batteryCapacity,\n    electricityRate,\n    chargingEfficiency\n  )\n  batteryCostPerCycle = batteryCost / batteryCycles\n\n  Plot.dists(\n    {\n      xScale: Scale.linear({ tickFormat: "$.2" }),\n      dists: [\n        {\n          name: "Electricity Costs",\n          value: unitAdjustment(totalElectricityCostToCharge),\n          showSummary: false,\n        },\n        {\n          name: "Battery Costs",\n          value: unitAdjustment(batteryCostPerCycle),\n          showSummary: false,\n        },\n      ],\n    }\n  )\n}\n\nexport calc = Calculator(\n  calcCosts,\n  {\n    title: "Costs of using a Laptop Computer Unplugged",\n    description: "When using a laptop unplugged, there is some damage done to the battery, and some cost of electricity usage. This calculator compares those two.",\n    inputs: [\n      Input.text(\n        {\n          name: "Battery Capacity, (Watt-Hours)",\n          default: "60",\n          description: "",\n        }\n      ),\n      Input.text({ name: "Electricity Rate", default: "0.2 to 0.3" }),\n      Input.text({ name: "Battery Cycles ", default: "1000 to 1500" }),\n      Input.text({ name: "Battery Cost ($)", default: "100 to 200" }),\n      Input.text({ name: "Hours of Use Per Cycle", default: "3 to 5" }),\n      Input.select(\n        {\n          name: "Unit to Show",\n          default: "Per Hour",\n          options: ["Per Hour", "Per Charge"],\n        }\n      ),\n    ],\n  }\n)\n',
  ],
  [
    "hub:ozziegooen/costs-of-sfo-to-uk-flight-claude",
    '// Generated mostly with Anthropic\'s Claude\n\n// Flight details\ndepartureAirport = "SFO"\ndestination = "London"\nflightDuration = 10 to 12 // hours\n\n// Ticket price\nticketPrice = 500 to 600\n\n// Value of time\nvalueOfTime = 50 to 80 // $/hour\ntimeCost = flightDuration * valueOfTime\n\n// Jet lag recovery time\njetLagRecovery = 1 to 3 // days\n\n// Environmental impact\nco2PerPassenger = normal(200, 50) // kg\ncostPerTonCo2 = 100 // $/tonne\nenvironmentalCost = co2PerPassenger * costPerTonCo2 / 1000\n\n// Aggregate costs\ntotalCost = ticketPrice + timeCost + jetLagRecovery * valueOfTime * 8 // 8 hours per day  + environmentalCost + socialValuePerTrip\n\ncostsChart = Plot.dists(\n  {\n    title: "Costs of different aspects, of a flights from SFO -> London",\n    dists: [\n      { name: "Ticket", value: ticketPrice },\n      { name: "Time", value: timeCost },\n      { name: "Jet Lag", value: jetLagRecovery * valueOfTime * 8 },\n      { name: "Environmental", value: environmentalCost },\n      { name: "Total", value: totalCost },\n    ],\n    xScale: Scale.symlog({ min: -100, constant: 50 }),\n  }\n)\n\ncostsChart',
  ],
  [
    "hub:ozziegooen/room-model",
    'binomialSample(trials, probability) = trials == 0 ? 0 : List(\n  trials,\n  {|| sample(Sym.bernoulli(sample(Dist(probability))))}\n)\n  -> sum\n\n_mxChoose(fns, prob) = fns[mx(List.upTo(0, List.length(fns) - 1), prob)\n  -> sample\n  -> round]\n\nmakeRoom(name, timeSpent, peopleCount, airChange, volume) = if name == "" ||\n  typeOf(name) != "String" then throw("Invalid name parameter") else {\n  ||\n  {\n    name: name,\n    timeSpent: Sym.lognormal(timeSpent),\n    peopleCount: Sym.lognormal(peopleCount),\n    averageAirChangePerHour: Sym.lognormal(airChange),\n    volume: Sym.lognormal(volume),\n  }\n}\n\noffice = makeRoom(\n  "Office",\n  { p5: 5, p95: 10 },\n  { p5: 10, p95: 30 },\n  { p5: 1, p95: 6 },\n  { p5: 280, p95: 840 }\n)\n\nclassRoom = makeRoom(\n  "Classroom",\n  { p5: 5, p95: 8 },\n  { p5: 15, p95: 35 },\n  { p5: 1, p95: 6 },\n  { p5: 195, p95: 315 }\n)\n\ngym = makeRoom(\n  "Gym",\n  { p5: 0.3, p95: 3 },\n  { p5: 10, p95: 60 },\n  { p5: 1, p95: 6 },\n  { p5: 200, p95: 1000 }\n)\n\nreligiousService = makeRoom(\n  "Religious Service",\n  { p5: 0.3, p95: 3 },\n  { p5: 5, p95: 100 },\n  { p5: 1, p95: 6 },\n  { p5: 200, p95: 1000 }\n)\n\npublicTransit = makeRoom(\n  "Public Transit",\n  { p5: 0.3, p95: 3 },\n  { p5: 5, p95: 20 },\n  { p5: 1, p95: 6 },\n  { p5: 200, p95: 1000 }\n)\n\nrestaurant = makeRoom(\n  "Restaurant",\n  { p5: 0.3, p95: 3 },\n  { p5: 5, p95: 50 },\n  { p5: 1, p95: 6 },\n  { p5: 200, p95: 1000 }\n)\n\nfactory = makeRoom(\n  "Factory",\n  { p5: 0.3, p95: 3 },\n  { p5: 20, p95: 200 },\n  { p5: 1, p95: 6 },\n  { p5: 2000, p95: 10000 }\n)\n\nsampleIfDist(e) = typeOf(e) == "Distribution" ? sample(e) : e\n\nsampleRoomDists(r) = {\n  name: r.name,\n  timeSpent: r.timeSpent,\n  peopleCount: round(sample(r.peopleCount)),\n  averageAirChangePerHour: sample(r.averageAirChangePerHour),\n  volume: sample(r.volume),\n}\n\n@showAs({|room| Calculator.make({ fn: room() })})\nexport room() = {\n  a = sample(uniform(0, 1))\n  _mxChoose(\n    [\n      office,\n      classRoom,\n      gym,\n      religiousService,\n      publicTransit,\n      restaurant,\n      factory,\n    ],\n    [0.4, 0.2, 0.05, 0.05, 0.3, 0.2, 0.1]\n  )\n}\n\nexamplePopulationInfectionPercentages = {\n  flu: 0.01 to 0.04,\n  covid: 0.01 to 0.05,\n}\n\naddInfectedCountToRoom(room, populationInfectionPercentages) = {\n  infectedPersonCounts = Dict.map(\n    populationInfectionPercentages,\n    {|v| binomialSample(room.peopleCount, v)}\n  )\n  totalInfectedCount = sum(Dict.values(infectedPersonCounts))\n  vulnerablePersonCount = totalInfectedCount == 0 ? 0 : max(\n    [room.peopleCount - totalInfectedCount, 0]\n  )\n  Dict.merge(room, { infectedPersonCounts, vulnerablePersonCount })\n}\n\nexport make(populationInfectionPercentages) = room()() -> sampleRoomDists\n  -> addInfectedCountToRoom(\n    populationInfectionPercentages\n  )\n\n//Sample, for testing\nm = make(examplePopulationInfectionPercentages)\n\nexport calc = Calculator(\n  make,\n  {\n    title: "Random Room Generator Calc",\n    autorun: false,\n    inputs: [\n      Input.textArea(\n        {\n          name: "Disease Infection Rates",\n          default: "{\n  flu: 0.01 to 0.04,\n  covid: 0.01 to 0.05,\n}",\n        }\n      ),\n    ],\n  }\n)\n',
  ],
  [
    "hub:ozziegooen/cost-of-reading-calculator",
    '/*\nHow long does it take to read different books?\nHow much does that cost, in counterfactual value, assuming that reading time is counterfactually valuable?\n\nThis is a very simple table of estimates. Inspired by a previous Guesstimate model.\n*/\n@hide\ncost(wpm, valuePerHour, words) = {\n  wordsPerHour = wpm * 120\n  words * (valuePerHour / wordsPerHour)\n}\n\n@name("Book Word Counts")\nwordCounts = [\n  { name: "Harry Potter 1", v: 76k },\n  { name: "Animal Farm", v: 29k },\n  { name: "Random blog post, 500 to 2k words", v: 500 to 2k },\n  { name: "The Great Gatsby", v: 47k },\n  { name: "Pride and Prejudice", v: 119k },\n  { name: "To Kill a Mockingbird", v: 100k },\n  { name: "The Fellowship of the Ring", v: 177k },\n  { name: "1984", v: 88k },\n  { name: "The Catcher in the Rye", v: 73k },\n  { name: "WORM", v: 1.78M },\n]\n  -> Tag.showAs(\n    {\n      |d|\n      Table(\n        d,\n        {\n          columns: [\n            { name: "Book", fn: {|r| r.name} },\n            { name: "Word Count", fn: {|r| r.v} },\n          ],\n        }\n      )\n    }\n  )\n\n@hide\ndollarFormat = "$.2f"\n\n@hide\ntable(readingSpeed, valueOfTimePerHour) = Table(\n  wordCounts,\n  {\n    columns: [\n      { name: "Name", fn: {|f| "**" + f.name + "**"} },\n      { name: "Word Count", fn: {|f| f.v} },\n      { name: "Hours to Read", fn: {|f| f.v / readingSpeed / 60} },\n      {\n        name: "Time Cost to Read",\n        fn: {\n          |f|\n          Plot.dist(\n            {\n              dist: cost(readingSpeed, Dist(valueOfTimePerHour), f.v),\n              showSummary: false,\n              xScale: Scale.symlog(\n                {\n                  min: 0.1,\n                  max: 10000,\n                  constant: 0.1,\n                  tickFormat: dollarFormat,\n                }\n              ),\n            }\n          )\n        },\n      },\n      {\n        name: "Time Cost to Read (mean)",\n        fn: {\n          |f|\n          cost(readingSpeed, Dist(valueOfTimePerHour), f.v) -> mean\n            -> Tag.format(\n              dollarFormat\n            )\n        },\n      },\n    ],\n  }\n)\n\n@name("Cost of Reading Various Books Calculator")\nexport calc = Calculator(\n  table,\n  {\n    title: "Cost of Reading Various Books",\n    description: "This calculator estimates the time and value costs for reading different books. Users input their reading speed (words per minute) and perceived hourly value of time (in dollars). The value of time should be for that which the user would replace with reading.",\n    inputs: [\n      Input.text(\n        {\n          name: "Your Reading Speed (words per minute)",\n          default: "200 to 300",\n          description: "Most people read at around 250wpm. Top readers can read around 700wpm.",\n        }\n      ),\n      Input.text(\n        { name: "Your Value of Time per Hour (Dollars)", default: "10 to 30" }\n      ),\n    ],\n  }\n)\n',
  ],
  [
    "hub:ozziegooen/helpers",
    'import "hub:ozziegooen/sTest" as sTest\n@hide\ntest = sTest.test\n@hide\nexpect = sTest.expect\n@hide\ndescribe = sTest.describe\n\n@doc(\n  "\n  round(num, n)\n  \n  Rounds the number `num` to `n` decimal places.\n  \n  Example:\n  round(3.14159, 2) -> \\"3.14\\"\n"\n)\nexport round(num, n) = {\n  asString = String.make(num)\n  splitString = String.split(asString, "")\n  if List.findIndex(splitString, {|r| r == "e"}) != -1 then {\n    // Handle scientific notation\n    parts = String.split(asString, "e")\n    decimalPart = parts[0]\n    exponentPart = parts[1]\n    roundedDecimalPart = if List.findIndex(\n      String.split(decimalPart, ""),\n      {|r| r == "."}\n    ) !=\n      -1 then {\n      decimalIndex = List.findIndex(\n        String.split(decimalPart, ""),\n        {|r| r == "."}\n      )\n      endIndex = min(\n        [decimalIndex + n + 1, List.length(String.split(decimalPart, ""))]\n      )\n      String.split(decimalPart, "") -> List.slice(0, endIndex) -> List.join("")\n    } else decimalPart\n    roundedDecimalPart + "e" + exponentPart\n  } else {\n    // Handle non-scientific notation numbers\n    decimalIndex = List.findIndex(splitString, {|r| r == "."})\n    if decimalIndex == -1 then asString else {\n      endIndex = min([decimalIndex + n + 1, List.length(splitString)])\n      splitString -> List.slice(0, endIndex) -> List.join("")\n    }\n  }\n}\n\n@name("round tests")\nroundTests = describe(\n  "Round Function Tests",\n  [\n    test("rounds a simple number", {|| expect(round(3.14159, 2)).toBe("3.14")}),\n    test("rounds a whole number", {|| expect(round(10, 2)).toBe("10")}),\n    test(\n      "rounds a number in scientific notation",\n      {|| expect(round(1.23e4, 2)).toBe("12300")}\n    ),\n    test(\n      "rounds a negative number",\n      {|| expect(round(-2.7182, 2)).toBe("-2.71")}\n    ),\n  ]\n)\n\n@doc(\n  "\n  formatTime(hours)\n  \n  Converts a number of hours to a formatted string indicating time in \n  seconds, minutes, hours, days, months, or years.\n  \n  Example:\n  formatTime(1) -> \\"**1** hours\\"\n  "\n)\nexport formatTime(hours) = {\n  secondsInMinute = 60\n  minutesInHour = 60\n  hoursInDay = 24\n  daysInMonth = 30\n  monthsInYear = 12\n\n  totalSeconds = hours * minutesInHour * secondsInMinute\n  totalMinutes = hours * minutesInHour\n  totalHours = hours\n  totalDays = hours / hoursInDay\n  totalMonths = totalDays / daysInMonth\n  totalYears = totalMonths / monthsInYear\n  round(n) = round(n, 2) -> {|r| "**" + r + "**"}\n\n  if totalYears >= 1 then round(totalYears) + " years" else if totalMonths >=\n    1 then round(totalMonths) + " months" else if totalDays >= 1 then round(\n    totalDays\n  ) +\n    " days" else if totalHours >= 1 then round(totalHours) +\n    " hours" else if totalMinutes >= 1 then round(totalMinutes) +\n    " minutes" else round(totalSeconds) + " seconds"\n}\n\n@name("formatTime tests")\nformatTimeTests = describe(\n  "FormatTime Function Tests",\n  [\n    test(\n      "formats time less than a minute",\n      {|| expect(formatTime(0.01)).toBe("**36** seconds")}\n    ),\n    test(\n      "formats time in hours",\n      {|| expect(formatTime(1)).toBe("**1** hours")}\n    ),\n    test(\n      "formats time in days",\n      {|| expect(formatTime(24)).toBe("**1** days")}\n    ),\n    test(\n      "formats time in months",\n      {|| expect(formatTime(720)).toBe("**1** months")}\n    ),\n    test(\n      "formats time in years",\n      {|| expect(formatTime(8760)).toBe("**1.01** years")}\n    ),\n  ]\n)\n\n@doc(\n  "## Linear or Quadratic Interpolation\n```squiggle\n@import(\'hub:ozziegooen/helpers\' as h)\n\nh.interpolate([{x: 0, y:10}, {x:10, y:20}], \'linear\')(4) -> 15\nh.interpolate([{x: 0, y:10}, {x:10, y:20}], \'quadratic\')(4) -> 11.6\n\n//makes a graph\nfoo(t:[0,30]) = h.interpolate([{x: 0, y:10}, {x:10, y:20}, {x:20, y:10}], \'quadratic\')(t) \n"\n)\nexport interpolate(points, type) = {\n  sortedPoints = List.sortBy(points, {|f| f.x}) //TODO: Sort, somehow\n  {\n    |x|\n    result = List.reduce(\n      sortedPoints,\n      sortedPoints[0].y,\n      {\n        |acc, point, i|\n        if i == 0 then acc else if sortedPoints[i - 1].x <= x &&\n          x <= point.x then {\n          leftPoint = sortedPoints[i - 1]\n          rightPoint = point\n\n          if type == "linear" then {\n            slope = (rightPoint.y - leftPoint.y) / (rightPoint.x - leftPoint.x)\n            leftPoint.y + slope * (x - leftPoint.x)\n          } else if type == "quadratic" then {\n            a = (rightPoint.y - leftPoint.y) / (rightPoint.x - leftPoint.x) ^ 2\n            b = -2 * a * leftPoint.x\n            c = leftPoint.y + a * leftPoint.x ^ 2\n            a * x ^ 2 + b * x + c\n          } else { foo: "Invalid interpolate type" }\n\n        } else if x > sortedPoints[i - 1].x then sortedPoints[List.length(\n          sortedPoints\n        ) -\n          1].y else acc\n      }\n    )\n    result\n  }\n}\n\ninterpolationTests = describe(\n  "Interpolation Function Tests",\n  [\n    test(\n      "linear interpolation within range",\n      {\n        ||\n        expect(\n          interpolate([{ x: 0, y: 10 }, { x: 10, y: 20 }], "linear")(4)\n        ).toBe(\n          14\n        )\n      }\n    ),\n    test(\n      "quadratic interpolation within range",\n      {\n        ||\n        expect(\n          interpolate([{ x: 0, y: 10 }, { x: 10, y: 20 }], "quadratic")(4)\n        ).toBe(\n          11.6\n        )\n      }\n    ),\n    test(\n      "linear interpolation at boundary",\n      {\n        ||\n        expect(\n          interpolate([{ x: 0, y: 10 }, { x: 10, y: 20 }], "linear")(0)\n        ).toBe(\n          10\n        )\n      }\n    ),\n    test(\n      "quadratic interpolation, additional points",\n      {\n        ||\n        expect(\n          interpolate(\n            [{ x: 0, y: 10 }, { x: 10, y: 20 }, { x: 20, y: 10 }],\n            "quadratic"\n          )(\n            15\n          )\n        ).toBe(\n          17.5\n        )\n      }\n    ),\n  ]\n)\n\n//myShape = [{ x: 4, y: 10 }, { x: 20, y: 40 }, { x: 30, y: 20 }]\n\nplot(fn, xPoints) = Plot.numericFn(\n  fn,\n  {\n    xScale: Scale.linear({ min: 0, max: 50 }),\n    xPoints: xPoints -> List.concat(List.upTo(0, 50)),\n  }\n)\n\n@hide\ncalculator_fn(shape, select) = {\n  xPoints = shape -> map({|r| r.x})\n  if select == "linear" then plot(\n    interpolate(shape, "linear"),\n    xPoints\n  ) else if select == "quadratic" then plot(\n    interpolate(shape, "quadratic"),\n    xPoints\n  ) else {\n    linear: plot(interpolate(shape, "linear"), xPoints),\n    quadratic: plot(interpolate(shape, "quadratic"), xPoints),\n  }\n}\n\n@name("Interpolation Calculator (for debugging)")\ninterpolationCalculator = Calculator(\n  calculator_fn,\n  {\n    title: "Interpolate: function demonstration",\n    description: "``interpolate(data, type=\'linear\'|\'quadratic\')``.  \n    \nYou have to enter data in the format of x and y values, as shown below, then get a function that can be called with any X to get any Y value.\n\n*Note: One important restriction is that these don\'t yet do a good job outside the data bounds. It\'s unclear what\'s best. I assume we should later give users options.*",\n    inputs: [\n      Input.textArea(\n        {\n          name: "Example input",\n          default: "[\n  { x: 4, y: 10 },\n  { x: 20, y: 30 },\n  { x: 30, y: 50 },\n  { x: 40, y: 30 },,\n]",\n        }\n      ),\n      Input.select(\n        {\n          name: "interpolate Type",\n          options: ["linear", "quadratic", "show both (for demonstration)"],\n          default: "show both (for demonstration)",\n        }\n      ),\n    ],\n  }\n)\n\n@startOpen\n@notebook\nreadme = [\n  "# Helpers Library\n\nA small library of various helper functions for numerical operations and formatting. Import this library into your Squiggle projects to utilize these utilities.\n\n## Import Usage\n\nTo use the functions from this library in your projects, import it as follows:\n\n```squiggle\n@import(\'hub:ozziegooen/helpers\') as h\n```\n## Functions Overview\n\n### round\nRounds a given number to a specified number of decimal places.\n\nExample:\n\n```squiggle\nh.round(3.423, 2) // Returns: \\"3.42\\"\n```",\n  Tag.getDoc(round),\n  "---",\n  "### formatTime\nConverts a given number of hours into a human-readable time format, such as seconds, minutes, hours, days, months, or years.\n\nExample:\n\n```squiggle\nh.formatTime(4.23) // Enter the number of hours and format the result\n```",\n  Tag.getDoc(formatTime),\n  "---",\n  "### interpolate\nProvides linear or quadratic interpolation for a set of points. Returns a function that can interpolate the y-value for any x-value.\n\nExample for Linear Interpolation:\n\n```squiggle\nh.interpolate([{x: 0, y: 10}, {x: 10, y: 20}], \'linear\')(4) // Returns: 15\n```\n\nExample for Quadratic Interpolation:\n\n```squiggle\nh.interpolate([{x: 0, y: 10}, {x: 10, y: 20}], \'quadratic\')(4) // Returns: 11.6\n```\n\n### Interpolation Calculator\nThis tool helps visualize and compare the results of linear and quadratic interpolations for a given set of data points. Below is an example use case integrated with the library.",\n  interpolationCalculator,\n]\n',
  ],
  [
    "hub:ozziegooen/room-model",
    'binomialSample(trials, probability) = trials == 0 ? 0 : List(\n  trials,\n  {|| sample(Sym.bernoulli(sample(Dist(probability))))}\n)\n  -> sum\n\n_mxChoose(fns, prob) = fns[mx(List.upTo(0, List.length(fns) - 1), prob)\n  -> sample\n  -> round]\n\nmakeRoom(name, timeSpent, peopleCount, airChange, volume) = if name == "" ||\n  typeOf(name) != "String" then throw("Invalid name parameter") else {\n  ||\n  {\n    name: name,\n    timeSpent: Sym.lognormal(timeSpent),\n    peopleCount: Sym.lognormal(peopleCount),\n    averageAirChangePerHour: Sym.lognormal(airChange),\n    volume: Sym.lognormal(volume),\n  }\n}\n\noffice = makeRoom(\n  "Office",\n  { p5: 5, p95: 10 },\n  { p5: 10, p95: 30 },\n  { p5: 1, p95: 6 },\n  { p5: 280, p95: 840 }\n)\n\nclassRoom = makeRoom(\n  "Classroom",\n  { p5: 5, p95: 8 },\n  { p5: 15, p95: 35 },\n  { p5: 1, p95: 6 },\n  { p5: 195, p95: 315 }\n)\n\ngym = makeRoom(\n  "Gym",\n  { p5: 0.3, p95: 3 },\n  { p5: 10, p95: 60 },\n  { p5: 1, p95: 6 },\n  { p5: 200, p95: 1000 }\n)\n\nreligiousService = makeRoom(\n  "Religious Service",\n  { p5: 0.3, p95: 3 },\n  { p5: 5, p95: 100 },\n  { p5: 1, p95: 6 },\n  { p5: 200, p95: 1000 }\n)\n\npublicTransit = makeRoom(\n  "Public Transit",\n  { p5: 0.3, p95: 3 },\n  { p5: 5, p95: 20 },\n  { p5: 1, p95: 6 },\n  { p5: 200, p95: 1000 }\n)\n\nrestaurant = makeRoom(\n  "Restaurant",\n  { p5: 0.3, p95: 3 },\n  { p5: 5, p95: 50 },\n  { p5: 1, p95: 6 },\n  { p5: 200, p95: 1000 }\n)\n\nfactory = makeRoom(\n  "Factory",\n  { p5: 0.3, p95: 3 },\n  { p5: 20, p95: 200 },\n  { p5: 1, p95: 6 },\n  { p5: 2000, p95: 10000 }\n)\n\nsampleIfDist(e) = typeOf(e) == "Distribution" ? sample(e) : e\n\nsampleRoomDists(r) = {\n  name: r.name,\n  timeSpent: r.timeSpent,\n  peopleCount: round(sample(r.peopleCount)),\n  averageAirChangePerHour: sample(r.averageAirChangePerHour),\n  volume: sample(r.volume),\n}\n\n@showAs({|room| Calculator.make({ fn: room() })})\nexport room() = {\n  a = sample(uniform(0, 1))\n  _mxChoose(\n    [\n      office,\n      classRoom,\n      gym,\n      religiousService,\n      publicTransit,\n      restaurant,\n      factory,\n    ],\n    [0.4, 0.2, 0.05, 0.05, 0.3, 0.2, 0.1]\n  )\n}\n\nexamplePopulationInfectionPercentages = {\n  flu: 0.01 to 0.04,\n  covid: 0.01 to 0.05,\n}\n\naddInfectedCountToRoom(room, populationInfectionPercentages) = {\n  infectedPersonCounts = Dict.map(\n    populationInfectionPercentages,\n    {|v| binomialSample(room.peopleCount, v)}\n  )\n  totalInfectedCount = sum(Dict.values(infectedPersonCounts))\n  vulnerablePersonCount = totalInfectedCount == 0 ? 0 : max(\n    [room.peopleCount - totalInfectedCount, 0]\n  )\n  Dict.merge(room, { infectedPersonCounts, vulnerablePersonCount })\n}\n\nexport make(populationInfectionPercentages) = room()() -> sampleRoomDists\n  -> addInfectedCountToRoom(\n    populationInfectionPercentages\n  )\n\n//Sample, for testing\nm = make(examplePopulationInfectionPercentages)\n\nexport calc = Calculator(\n  make,\n  {\n    title: "Random Room Generator Calc",\n    autorun: false,\n    inputs: [\n      Input.textArea(\n        {\n          name: "Disease Infection Rates",\n          default: "{\n  flu: 0.01 to 0.04,\n  covid: 0.01 to 0.05,\n}",\n        }\n      ),\n    ],\n  }\n)\n',
  ],
  [
    "hub:ozziegooen/movies-2024-July-prediction-tournament",
    '@startOpen\n@name("Documentation: Start Here!")\ndocumentation = "This model contains the information necessary to support a forecasting competition to predict the ratings of upcoming movies on IMDB, Metacritic, and Rotten Tomatoes.\n\nTo participate in the competition, write a function matching this signature:  \n```\nfn(\n  time: Date between 2024-04-01 and 2024-06-01,  \n  movieUrl: Metacritic movie ID like \\"boy-kills-world\\" or \\"challengers\\",\n  scoreType: One of [\\"imdb\\", \\"metacritic\\", \\"rottenTomatoes\\"]\n) => probability distribution\n```\n\nThe function should output a probability distribution representing the predicted score for the given `movie` on the specified `scoreType` platform at the input `time`. \n\nA few key points:\n- The function will only be scored once the first reviews are published for each movie. No need to handle pre-release periods.\n- IMDB and Metacritic scores range from 0-10. Rotten Tomatoes scores range from 0-100. \n- Aim to output a continuous distribution like `Dist.normal()`. Other dist types will be auto-converted which may be suboptimal.\n- Performance will be evaluated using proper scoring rules that assess the accuracy and calibration of the predicted distributions.\n\nThe model includes information on 60+ upcoming films, example functions to use as starting points, and useful helper functions. Get started by checking out:\n- `movies` - Release date, genre, studio and Metacritic URL for each movie \n- `exampleFunctions` - Sample prediction functions to build on or take inspiration from\n- `scoreData` - Details on the different scoring platforms\n- `validateLib` - Check if your function outputs properly ranged distributions\n- `visualizations` - Interactively visualize your function\'s predictions\n\nGood luck! Enjoy nerding out on movies while leveling up your probabalistic forecasting skills. May the best cinephile win!"\n\n// https://www.metacritic.com/news/upcoming-movie-release-dates-schedule/\n\n@name("Upcoming Movie Data, from Apr 20 2024, from Metacritic")\n@doc(\n  "See: [Metacritic Upcoming Release Schedule](https://www.metacritic.com/news/upcoming-movie-release-dates-schedule/).\nI used Claude Haiku for parsing/filtering the HTML, because speed + length was important.\n\nSome interesting box office numbers are here, for future use: https://www.boxofficemojo.com/year/world/?ref_=bo_nb_in_tab"\n)\n@startClosed\nexport movies = {\n  @startClosed\n  data = [\n    [\n      "Boy Kills World",\n      "boy-kills-world",\n      "2024-04-26",\n      "Lionsgate/Roadside Attractions",\n      "Action/Thriller",\n    ],\n    [\n      "Challengers",\n      "challengers",\n      "2024-04-26",\n      "Amazon MGM Studios",\n      "Drama/Sports",\n    ],\n    ["Unsung Hero", "unsung-hero", "2024-04-26", "Lionsgate", "Drama/Family"],\n    [\n      "Kingdom of the Planet of the Apes",\n      "kingdom-of-the-planet-of-the-apes",\n      "2024-05-10",\n      "20th Century Studios",\n      "Action/Sci-fi",\n    ],\n    [\n      "Furiosa: A Mad Max Saga",\n      "furiosa-a-mad-max-saga",\n      "2024-05-24",\n      "Warner Bros.",\n      "Action/Sci-fi/Thriller",\n    ],\n    [\n      "The Garfield Movie",\n      "the-garfield-movie",\n      "2024-05-24",\n      "Sony",\n      "Animation/Family",\n    ],\n    ["Sight", "sight", "2024-05-24", "Angel Studios", "Drama"],\n    ["Ezra", "ezra-2023", "2024-05-31", "Bleecker Street", "Comedy"],\n    [\n      "Bad Boys: Ride or Die",\n      "bad-boys-ride-or-die",\n      "2024-06-07",\n      "Sony",\n      "Action/Comedy",\n    ],\n    [\n      "Inside Out 2",\n      "inside-out-2",\n      "2024-06-14",\n      "Disney/Pixar",\n      "Animation/Family",\n    ],\n    ["The Watchers", "the-watchers", "2024-06-14", "Warner Bros.", "Horror"],\n    [\n      "The Bikeriders",\n      "the-bikeriders",\n      "2024-06-21",\n      "Focus Features",\n      "Drama",\n    ],\n    ["Janet Planet", "janet-planet", "2024-06-21", "A24", "Drama"],\n    ["Daddio", "daddio", "2024-06-28", "Sony Pictures Classics", "Drama"],\n    [\n      "Horizon: An American Saga Chapter 1",\n      "horizon-an-american-saga---chapter-1",\n      "2024-06-28",\n      "Warner Bros.",\n      "Western",\n    ],\n    [\n      "A Quiet Place: Day One",\n      "a-quiet-place-day-one",\n      "2024-06-28",\n      "Paramount",\n      "Horror/Thriller",\n    ],\n    ["MaXXXine", "maxxxine", "2024-07-05", "A24", "Horror"],\n    [\n      "Fly Me to the Moon",\n      "fly-me-to-the-moon",\n      "2024-07-12",\n      "Sony/Apple",\n      "Rom-com",\n    ],\n    ["Longlegs", "longlegs", "2024-07-12", "Neon", "Horror/Thriller"],\n    [\n      "Deadpool & Wolverine",\n      "deadpool-wolverine",\n      "2024-07-26",\n      "Disney/Marvel Studios",\n      "Action/Comedy/Sci-fi",\n    ],\n    ["Ddi ()", "didi", "2024-07-26", "Focus Features", "Comedy/Drama"],\n    [\n      "The Fabulous Four",\n      "the-fabulous-four",\n      "2024-07-26",\n      "Bleecker Street",\n      "Comedy",\n    ],\n    [\n      "Harold and the Purple Crayon",\n      "harold-and-the-purple-crayon",\n      "2024-08-02",\n      "Sony",\n      "Animation/Family",\n    ],\n    [\n      "Borderlands",\n      "borderlands",\n      "2024-08-09",\n      "Lionsgate",\n      "Sci-fi/Action/Comedy",\n    ],\n    ["Cuckoo", "cuckoo", "2024-08-09", "Neon", "Horror/Thriller"],\n    ["The Fire Inside", "the-fire-inside", "2024-08-09", "MGM", "Drama/Sports"],\n    ["It Ends With Us", "it-ends-with-us", "2024-08-09", "Sony", "Drama"],\n    ["Trap", "trap", "2024-08-09", "Warner Bros.", "Horror/Thriller"],\n    [\n      "Alien: Romulus",\n      "alien-romulus",\n      "2024-08-16",\n      "20th Century Studios",\n      "Sci-fi/Horror",\n    ],\n    [\n      "Horizon: An American Saga Chapter 2",\n      "horizon-an-american-saga---chapter-2",\n      "2024-08-16",\n      "Warner Bros.",\n      "Western",\n    ],\n    [\n      "Ryan\'s World The Movie: Titan Universe Adventure",\n      "ryans-world-the-movie-titan-universe-adventure",\n      "2024-08-16",\n      "Falling Forward Films",\n      "Animation/Family",\n    ],\n    [\n      "Blink Twice",\n      "blink-twice",\n      "2024-08-23",\n      "Amazon MGM Studios",\n      "Drama/Thriller",\n    ],\n    [\n      "The Crow 2024",\n      "the-crow-2024",\n      "2024-08-23",\n      "Lionsgate",\n      "Action/Fantasy",\n    ],\n    ["The Forge", "the-forge", "2024-08-23", "Sony", "Drama"],\n    ["Slingshot", "slingshot", "2024-08-23", "Bleecker Street", "Sci-fi"],\n    [\n      "City of Dreams",\n      "city-of-dreams",\n      "2024-08-30",\n      "Roadside Attractions",\n      "Drama/Thriller",\n    ],\n    [\n      "Kraven the Hunter",\n      "kraven-the-hunter",\n      "2024-08-30",\n      "Sony",\n      "Action-adventure/Sci-fi",\n    ],\n    ["Reagan", "reagan", "2024-08-30", "ShowBiz Direct", "Drama/Biopic"],\n    [\n      "Beetlejuice Beetlejuice 2024 A.D.",\n      "beetlejuice-beetlejuice-2024-ad",\n      "2024-09-06",\n      "Warner Bros.",\n      "Fantasy/Horror/Comedy",\n    ],\n    [\n      "Speak No Evil",\n      "speak-no-evil",\n      "2024-09-13",\n      "Universal/Blumhouse",\n      "Horror",\n    ],\n    ["Lee", "lee", "2024-09-20", "Roadside Attractions/Vertical", "Drama"],\n    [\n      "Transformers One",\n      "transformers-one",\n      "2024-09-20",\n      "Paramount",\n      "Animation/Action/Sci-fi",\n    ],\n    [\n      "The Wild Robot",\n      "the-wild-robot",\n      "2024-09-20",\n      "Universal",\n      "Animation/Family",\n    ],\n    ["Wolfs", "wolfs", "2024-09-20", "Sony/Apple", "Action/Thriller"],\n    ["Never Let Go", "never-let-go", "2024-09-27", "Lionsgate", "Horror"],\n    [\n      "Joker: Folie  Deux",\n      "joker-folie-s-deux",\n      "2024-10-04",\n      "Warner Bros.",\n      "Drama/Thriller/Musical",\n    ],\n    ["White Bird", "white-bird", "2024-10-04", "Lionsgate", "Drama"],\n    [\n      "Piece by Piece",\n      "piece-by-piece",\n      "2024-10-11",\n      "Focus Features",\n      "Animation/Documentary",\n    ],\n    ["Smile 2", "smile-2", "2024-10-18", "Paramount", "Horror/Thriller"],\n    [\n      "Terrifier 3",\n      "terrifier-3",\n      "2024-10-25",\n      "Cineverse/Iconic Events",\n      "Horror",\n    ],\n    [\n      "Venom: The Last Dance",\n      "venom-the-last-dance",\n      "2024-10-25",\n      "Sony",\n      "Sci-fi/Action",\n    ],\n  ]\n\n  table = Table.make(\n    data\n      -> List.map(\n        {\n          |m|\n          {\n            name: m[0],\n            url: m[1],\n            releaseDate: Date(m[2]),\n            studio: m[3],\n            genre: m[4],\n          }\n        }\n      ),\n    {\n      columns: [\n        {\n          name: "Name/Link",\n          fn: {\n            |d|\n            "[" + d.name + "](https://www.metacritic.com/movie/" + d.url + ")"\n          },\n        },\n        { name: "ID", fn: {|d| d.url} },\n        {\n          name: "Release Date",\n          fn: {|d| d.releaseDate},\n          format: {|d| d.format("YYYY-MM-DD")},\n          sortValue: {|d| d.releaseDate},\n        },\n        { name: "Studio", fn: {|d| d.studio} },\n        { name: "Genre", fn: {|d| d.genre} },\n      ],\n      sortColumn: "Release Date",\n    }\n  )\n  { data, table }\n}\n\n@startClosed\n@name("Manifold Markets Comparison Questions")\n@doc(\n  "I found some questions on Manifold Markets that were similar to this. Here\'s a few of them. This is useful for seeing how one\'s Movie Function would perform on them."\n)\nmanifoldComparisonQuestions = {\n  data = [\n    {\n      questionName: "Will \\"Challengers\\" (2024) have a Metacritic score >84?",\n      prediction: 0.37,\n      numberOfForecasters: 8,\n      params: {\n        movieUrl: "challengers",\n        date: 2024,\n        param: "metacritic",\n        query: {|e| 1 - cdf(e, 84)},\n      },\n    },\n    {\n      questionName: "Will \\"Challengers\\" (2024) have >94% critics score on Rotten Tomatoes?",\n      prediction: 0.97,\n      numberOfForecasters: 23,\n      params: {\n        movieUrl: "challengers",\n        date: 2024,\n        param: "rottenTomatoes",\n        query: {|e| 1 - cdf(e, 94)},\n      },\n    },\n    {\n      questionName: "Will \\"Challengers\\" (2024) have >86% critics score on Rotten Tomatoes?",\n      prediction: 0.97,\n      numberOfForecasters: 23,\n      params: {\n        movieUrl: "challengers",\n        date: 2024,\n        param: "rottenTomatoes",\n        query: {|e| 1 - cdf(e, 86)},\n      },\n    },\n    {\n      questionName: "Will \\"Challengers\\" (2024) have a Metacritic score >75?",\n      prediction: 0.94,\n      numberOfForecasters: 4,\n      params: {\n        movieUrl: "challengers",\n        date: 2024,\n        param: "metacritic",\n        query: {|e| 1 - cdf(e, 75)},\n      },\n    },\n  ]\n  { data, }\n}\n\n@name("Data about Score Types")\n@doc(\n  "The three score types are *IMDB*, *Metacritic*, and *Rotten Tomatoes*. The first two have scores that range from 0-10, and Rotten Tomatoes goes from 0 to 100. Included in this object is a `truncateScore` function, that takes in a probability distribution, and truncates out the parts not in the relevant range."\n)\n@startClosed\nexport scoreData = {\n  @startOpen\n  types = ["imdb", "metacritic", "rottenTomatoes"]\n  @startClosed\n  range = { imdb: [0, 10], metacritic: [0, 100], rottenTomatoes: [0, 100] }\n  truncateScore(score, type) = truncate(score, range[type][0], range[type][1])\n\n  { types, range, truncateScore }\n}\n\n@startClosed\n@name("Internal Libraries")\nlib = {\n  randomlyPickFromList(list) = uniform(0, List.length(list) - 1) -> Dist.sample\n    -> Number.round\n    -> {|i| list[i]}\n\n  randomDateBetween(start, end) = {\n    duration = end - start\n    randomFraction = sample(uniform(0, 1))\n    start + duration * randomFraction\n  }\n\n  isCloseTo(a, b, tolerance) = abs(a - b) < tolerance\n\n  { randomlyPickFromList, randomDateBetween, isCloseTo }\n}\n\n@startClosed\n@name("Random Function Input Data Generation Libraries")\nrandomNess = {\n  first = Date(2024, 4, 1)\n  last = Date(2024, 6, 1)\n\n  getMovie() = lib.randomlyPickFromList(movies.data)\n  getProperty() = lib.randomlyPickFromList(scoreData.types)\n  getDate() = lib.randomDateBetween(first, last)\n  getAll() = { movie: getMovie(), property: getProperty(), date: getDate() }\n\n  runOnFn(fn) = {\n    args = getAll()\n    result = fn(args.date, args.movie[1], args.property)\n    { args, result }\n  }\n\n  { getMovie, getProperty, getDate, getAll, runOnFn }\n}\n\n@startClosed\nvalidateLib = {\n  tryFnOnRandomResult(fn) = {\n    args = randomNess.getAll()\n    result = fn(args.date, args.movie[1], args.property)\n    { args, result }\n  }\n\n  verifyNTimes(fn, n) = {\n    responses = List.make(\n      n,\n      {\n        ||\n        run = tryFnOnRandomResult(fn)\n        resultSupport = PointSet.support(run.result).segments[0]\n        intendedRange = scoreData.range[run.args.property]\n        min = lib.isCloseTo(resultSupport[0], intendedRange[0], 0.1)\n        max = lib.isCloseTo(resultSupport[1], intendedRange[1], 0.1)\n        if min && max then false else {\n          error: "Mismatch between intendedRange and resultSupport",\n          intendedRange,\n          resultSupport,\n          result: run.result,\n        }\n      }\n    )\n    errorResponses = responses -> List.filter({|r| r != false})\n\n    { errorResponses, isValid: List.length(errorResponses) == 0 }\n  }\n\n  validate(fn) = {\n    verified = verifyNTimes(fn, 20)\n    verified.isValid ? "" : verified.errorResponses -> List.map({|v| v.error})\n      -> List.join(\n        "|"\n      )\n  }\n\n  validate\n}\n\n@name("Movie Predictions Specification")\nexport spec = Spec.make(\n  {\n    name: "Movie Predictions Specification",\n    documentation: "",\n    validate: validateLib,\n  }\n)\n\n@name("Example Functions")\nexampleFunctions = {\n  @startClosed\n  @name("Prior Function for Movie Predictions Specification")\n  @spec(spec)\n  @location\n  priorsFn = {\n    perScoreType = {\n      imdb: scoreData.truncateScore(Sym.normal(6.5, 2), "imdb"),\n      metacritic: scoreData.truncateScore(Sym.normal(60, 20), "metacritic"),\n      rottenTomatoes: scoreData.truncateScore(\n        Sym.normal(60, 20),\n        "rottenTomatoes"\n      ),\n    }\n\n    fn(\n      time: [Date(2024, 4, 1), Date(2024, 6, 1)],\n      movie,\n      scoreType\n    ) = perScoreType[scoreType]\n    fn\n  }\n\n  @startClosed\n  @name("Simple Example Function for Movie Predictions Spec")\n  @spec(spec)\n  @location\n  simpleExample = {\n    perScoreType = {\n      imdb: scoreData.truncateScore(Sym.normal(6.5, 1), "imdb"),\n      metacritic: scoreData.truncateScore(Sym.normal(60, 3), "metacritic"),\n      rottenTomatoes: scoreData.truncateScore(\n        Sym.normal(50, 9),\n        "rottenTomatoes"\n      ),\n    }\n\n    fn(\n      time: [Date(2024, 4, 1), Date(2024, 6, 1)],\n      movie,\n      scoreType\n    ) = perScoreType[scoreType]\n    fn\n  }\n\n  @startClosed\n  @name("Complicated Example Function for Movie Predictions Spec")\n  @spec(spec)\n  @location\n  complicatedExample = {\n    baseScoreDistAttributes = {\n      imdb: { mean: 6.8, stdev: 1.2 },\n      metacritic: { mean: 72, stdev: 15 },\n      rottenTomatoes: { mean: 70, stdev: 20 },\n    }\n\n    adjustScore(mean, adjustment, scoreType) = if scoreType ==\n      "imdb" then mean + adjustment / 10 else if scoreType ==\n      "metacritic" then mean + adjustment else mean + adjustment * 1.2\n\n    adjustments = {\n      "boy-kills-world": { amount: -5, stdevMultiplier: 1.1 },\n      challengers: { amount: 25, stdevMultiplier: 0.8 },\n      "unsung-hero": { amount: 0, stdevMultiplier: 1 },\n      "kingdom-of-the-planet-of-the-apes": { amount: 5, stdevMultiplier: 1 },\n      "furiosa-a-mad-max-saga": { amount: 5, stdevMultiplier: 1 },\n      "the-garfield-movie": { amount: -10, stdevMultiplier: 1.2 },\n      sight: { amount: 0, stdevMultiplier: 1 },\n      "ezra-2023": { amount: 0, stdevMultiplier: 1 },\n      "bad-boys-ride-or-die": { amount: 0, stdevMultiplier: 1 },\n      "inside-out-2": { amount: 8, stdevMultiplier: 0.9 },\n      "the-watchers": { amount: -5, stdevMultiplier: 1.1 },\n      "the-bikeriders": { amount: 0, stdevMultiplier: 1 },\n      "janet-planet": { amount: 0, stdevMultiplier: 1 },\n      daddio: { amount: 0, stdevMultiplier: 1 },\n      "horizon-an-american-saga---chapter-1": { amount: 0, stdevMultiplier: 1 },\n      "a-quiet-place-day-one": { amount: 5, stdevMultiplier: 1 },\n      maxxxine: { amount: -5, stdevMultiplier: 1.1 },\n      "fly-me-to-the-moon": { amount: 0, stdevMultiplier: 1 },\n      longlegs: { amount: 0, stdevMultiplier: 1 },\n      "deadpool-wolverine": { amount: 10, stdevMultiplier: 0.9 },\n      didi: { amount: 0, stdevMultiplier: 1 },\n      "the-fabulous-four": { amount: 0, stdevMultiplier: 1 },\n      "harold-and-the-purple-crayon": { amount: 0, stdevMultiplier: 1 },\n      borderlands: { amount: 0, stdevMultiplier: 1 },\n      cuckoo: { amount: 0, stdevMultiplier: 1 },\n      "the-fire-inside": { amount: 0, stdevMultiplier: 1 },\n      "it-ends-with-us": { amount: 0, stdevMultiplier: 1 },\n      trap: { amount: 0, stdevMultiplier: 1 },\n      "alien-romulus": { amount: 5, stdevMultiplier: 1 },\n      "horizon-an-american-saga---chapter-2": { amount: 0, stdevMultiplier: 1 },\n      "ryans-world-the-movie-titan-universe-adventure": {\n        amount: -10,\n        stdevMultiplier: 1.2,\n      },\n      "blink-twice": { amount: 0, stdevMultiplier: 1 },\n      "the-crow-2024": { amount: -5, stdevMultiplier: 1.1 },\n      "the-forge": { amount: 0, stdevMultiplier: 1 },\n      slingshot: { amount: 0, stdevMultiplier: 1 },\n      "city-of-dreams": { amount: 0, stdevMultiplier: 1 },\n      "kraven-the-hunter": { amount: -8, stdevMultiplier: 1.2 },\n      reagan: { amount: 0, stdevMultiplier: 1 },\n      "beetlejuice-beetlejuice-2024-ad": { amount: 0, stdevMultiplier: 1 },\n      "speak-no-evil": { amount: -5, stdevMultiplier: 1.1 },\n      lee: { amount: 0, stdevMultiplier: 1 },\n      "transformers-one": { amount: 0, stdevMultiplier: 1 },\n      "the-wild-robot": { amount: 0, stdevMultiplier: 1 },\n      wolfs: { amount: 0, stdevMultiplier: 1 },\n      "never-let-go": { amount: 0, stdevMultiplier: 1 },\n      "joker-folie-s-deux": { amount: 10, stdevMultiplier: 0.9 },\n      "white-bird": { amount: 0, stdevMultiplier: 1 },\n      "piece-by-piece": { amount: 0, stdevMultiplier: 1 },\n      "smile-2": { amount: 0, stdevMultiplier: 1 },\n      "terrifier-3": { amount: -5, stdevMultiplier: 1.1 },\n      "venom-the-last-dance": { amount: 0, stdevMultiplier: 1 },\n    }\n\n    fn(time: [Date(2024, 4, 1), Date(2024, 6, 1)], movie, scoreType) = {\n      distAttributes = baseScoreDistAttributes[scoreType]\n      stdev = if scoreType == "imdb" then 1.2 else if scoreType ==\n        "metacritic" then 15 else 20\n\n      if Dict.has(adjustments, movie) then {\n        adjustment = adjustments[movie].amount\n        stdevMultiplier = adjustments[movie].stdevMultiplier\n        newMean = adjustScore(distAttributes.mean, adjustment, scoreType)\n        scoreData.truncateScore(\n          Sym.normal(newMean, distAttributes.stdev * stdevMultiplier),\n          scoreType\n        )\n      } else scoreData.truncateScore(\n        Sym.normal(distAttributes.mean, distAttributes.stdev),\n        scoreType\n      )\n    }\n\n    fn\n  }\n\n  { priorsFn, simpleExample, complicatedExample }\n}\n\n@name("Visualizations")\nvisualizations = {\n  _movieDataWithUrls(movies) = movies.data\n    -> List.map(\n      {\n        |movieData|\n        { movie: movieData[1], name: movieData[0], url: movieData[1] }\n      }\n    )\n\n  @location\n  @startClosed\n  movieTable(date, scorePredictionFn) = {\n    movieData = _movieDataWithUrls(movies)\n\n    columns = List.concat(\n      [\n        {\n          name: "Name",\n          fn: {\n            |movie|\n            "[" + movie.name + "](https://www.metacritic.com/movie/" +\n              movie.url +\n              ")"\n          },\n          asMarkdown: true,\n        },\n      ],\n      scoreData.types\n        -> List.map(\n          {\n            |scoreType|\n            [\n              {\n                name: scoreType,\n                fn: {\n                  |movie|\n                  yourDist = scorePredictionFn(date, movie.movie, scoreType)\n                  priorDist = exampleFunctions.priorsFn(\n                    date,\n                    movie.movie,\n                    scoreType\n                  )\n\n                  Plot.dists(\n                    [\n                      { name: "prior", value: priorDist },\n                      { name: "prediction", value: yourDist },\n                    ],\n                    {\n                      xScale: Scale.linear(\n                        {\n                          min: scoreData.range[scoreType][0],\n                          max: scoreData.range[scoreType][1],\n                        }\n                      ),\n                      showSummary: false,\n                    }\n                  )\n                },\n              },\n              {\n                name: scoreType + " KL Divergence",\n                fn: {\n                  |movie|\n                  yourDist = scorePredictionFn(date, movie.movie, scoreType)\n                  priorDist = exampleFunctions.priorsFn(\n                    date,\n                    movie.movie,\n                    scoreType\n                  )\n                  Dist.klDivergence(priorDist, yourDist)\n                },\n              },\n            ]\n          }\n        )\n        -> List.flatten\n    )\n\n    Table.make(movieData, { columns: columns })\n  }\n\n  @location\n  @startClosed\n  manifoldComparisonTable(fn) = Table.make(\n    manifoldComparisonQuestions.data,\n    {\n      columns: [\n        { name: "Question", fn: {|q| q.questionName} },\n        { name: "Manifold Trader Count", fn: {|q| q.numberOfForecasters} },\n        { name: "Manifold Prediction", fn: {|q| q.prediction} },\n        {\n          name: "Your Prediction",\n          fn: {\n            |q|\n            date = Date(q.params.date, 6, 1)\n            dist = fn(date, q.params.movieUrl, q.params.param)\n            q.params.query(dist)\n          },\n        },\n      ],\n    }\n  )\n\n  calculator = Calculator.make(\n    {\n      |model, visualization|\n      fn = if Dict.has(\n        exampleFunctions,\n        model\n      ) then exampleFunctions[model] else exampleFunctions.priorsFn\n\n      allTables = { movieTable, manifoldComparisonTable }\n      visualizationFn = if Dict.has(\n        allTables,\n        visualization\n      ) then allTables[visualization] else allTables.movieTable\n\n      if visualization == "movieTable" then allTables.movieTable(\n        Date(2024, 6, 1),\n        fn\n      ) else allTables.manifoldComparisonTable(fn)\n    },\n    {\n      title: "Movie Score Prediction Visualization",\n      autorun: false,\n      inputs: [\n        Input.select(\n          {\n            name: "Model",\n            description: "Choose an example model",\n            options: ["priorsFn", "simpleExample", "complicatedExample"],\n            default: "priorsFn",\n          }\n        ),\n        Input.select(\n          {\n            name: "Visualization",\n            description: "Choose a visualization",\n            options: ["movieTable", "manifoldComparisonTable"],\n            default: "movieTable",\n          }\n        ),\n      ],\n    }\n  )\n\n  { movieTable, manifoldComparisonTable, calculator }\n}\n\n@name("Model-Specific Visualization")\nexport modelVisualization(model) = {\n  _movieDataWithUrls(movies) = movies.data\n    -> List.map(\n      {\n        |movieData|\n        { movie: movieData[1], name: movieData[0], url: movieData[1] }\n      }\n    )\n\n  @location\n  @startClosed\n  movieTable(date, scorePredictionFn) = {\n    movieData = _movieDataWithUrls(movies)\n\n    columns = List.concat(\n      [\n        {\n          name: "Name",\n          fn: {\n            |movie|\n            "[" + movie.name + "](https://www.metacritic.com/movie/" +\n              movie.url +\n              ")"\n          },\n          asMarkdown: true,\n        },\n      ],\n      scoreData.types\n        -> List.map(\n          {\n            |scoreType|\n            [\n              {\n                name: scoreType,\n                fn: {\n                  |movie|\n                  yourDist = scorePredictionFn(date, movie.movie, scoreType)\n                  priorDist = exampleFunctions.priorsFn(\n                    date,\n                    movie.movie,\n                    scoreType\n                  )\n\n                  Plot.dists(\n                    [\n                      { name: "prior", value: priorDist },\n                      { name: "prediction", value: yourDist },\n                    ],\n                    {\n                      xScale: Scale.linear(\n                        {\n                          min: scoreData.range[scoreType][0],\n                          max: scoreData.range[scoreType][1],\n                        }\n                      ),\n                      showSummary: false,\n                    }\n                  )\n                },\n              },\n              {\n                name: scoreType + " KL Divergence",\n                fn: {\n                  |movie|\n                  yourDist = scorePredictionFn(date, movie.movie, scoreType)\n                  priorDist = exampleFunctions.priorsFn(\n                    date,\n                    movie.movie,\n                    scoreType\n                  )\n                  Dist.klDivergence(priorDist, yourDist)\n                },\n              },\n            ]\n          }\n        )\n        -> List.flatten\n    )\n\n    Table.make(movieData, { columns: columns })\n  }\n\n  @location\n  @startClosed\n  manifoldComparisonTable(fn) = Table.make(\n    manifoldComparisonQuestions.data,\n    {\n      columns: [\n        { name: "Question", fn: {|q| q.questionName} },\n        { name: "Manifold Trader Count", fn: {|q| q.numberOfForecasters} },\n        { name: "Manifold Prediction", fn: {|q| q.prediction} },\n        {\n          name: "Your Prediction",\n          fn: {\n            |q|\n            date = Date(q.params.date, 6, 1)\n            dist = fn(date, q.params.movieUrl, q.params.param)\n            q.params.query(dist)\n          },\n        },\n      ],\n    }\n  )\n\n  calculator = Calculator.make(\n    {\n      |visualization|\n\n      allTables = { movieTable, manifoldComparisonTable }\n      visualizationFn = if Dict.has(\n        allTables,\n        visualization\n      ) then allTables[visualization] else allTables.movieTable\n\n      if visualization == "movieTable" then allTables.movieTable(\n        Date(2024, 6, 1),\n        model\n      ) else allTables.manifoldComparisonTable(model)\n    },\n    {\n      title: "Movie Score Prediction Visualization",\n      autorun: false,\n      inputs: [\n        Input.select(\n          {\n            name: "Visualization",\n            description: "Choose a visualization",\n            options: ["movieTable", "manifoldComparisonTable"],\n            default: "movieTable",\n          }\n        ),\n      ],\n    }\n  )\n\n  { movieTable, manifoldComparisonTable, calculator }\n}',
  ],
  [
    "hub:blueprint-biosecurity/burden-of-resp-disease",
    '// This is an uncertainty analysis of the annual burden of respiratory disease from long range aeorosol transmission in the US. See this documentation for why we have chosen these parameter values: https://docs.google.com/document/d/1Tnyb5WHn727QrFKknFiMyqSm68fYG8tTlgfHedjzT98/edit\n\n//Background parameters\n@name("QALY value")\nqaly = 750k\n@name("QALY adjustment")\nqaly_adjustment = normal(0.7,0.2)\n\n@name("Long range aerosol transmission rates")\naeorol_rates = {\n  flu: 20% to 80%,\n  lris_uris: 10% to 50%,\n  non_flu_lris_uris: 2.5% to 15%,\n  covid: 20% to 80%\n}\n\n@name("Annual years of life lost (YLLs)")\nylls = {\n  lris: 1061123.68 to 1220901.28,\n  uris: 3473.37 to 3897.31,\n  covid: (60402 to 127k)*(4 to 10) // annual deaths * averae YLL\n}\n\n@name("Annual years lived with disability (YLDs)")\nylds = {\n  lris: 5781.43 to 11476.39,\n  uris: 176624.98 to 438816.65,\n  covid: (191957.23 to 1089479.34)*((60402 to 127k)/(474400.13 to 494812.01))/(1.5 to 4) // YLDs in 2021 * (expected annual deaths/deaths in 2021)/ (pandemic years 1.5 to 4 times worse than endemic years)\n}\n\n@name("Productivity estimates")\nprod_ests = {\n  flu: (4.8B to 13.6B)*1.32,\n  non_flu_lris_uris: (31.2B to 48B)*(22.5B/40B)*1.76 // range for all costs * (productivity median cost / total median cost) * 1.76 conversion to 2024 dollars\n}\n\n// Mortality burden\n@name("LRI mortality burden")\nlri_mortality = ylls.lris*aeorol_rates.lris_uris*qaly*qaly_adjustment\n\n@name("URI mortality burden")\nuri_mortality = ylls.uris*aeorol_rates.lris_uris*qaly*qaly_adjustment\n\n@name("Covid-19 mortality burden")\ncovid_mortality = ylls.covid*aeorol_rates.covid*qaly*qaly_adjustment\n\n@name("Total mortality burden")\nmortality = lri_mortality+uri_mortality+covid_mortality\n\n// Illness burden\n@name("LRI illness burden")\nlri_illness = ylds.lris*aeorol_rates.lris_uris*qaly\n\n@name("URI illness burden")\nuri_illness = ylds.uris*aeorol_rates.lris_uris*qaly\n\n@name("Covid-19 illness burden")\ncovid_illness = ylds.covid*aeorol_rates.covid*qaly\n\n@name("Total illness burden")\nillness = lri_illness+uri_illness+covid_illness\n\n// Productivity burden\n@name("Influenza productivity burden")\nflu_productivity = prod_ests.flu*aeorol_rates.flu\n\n@name("Non-influenza LRI/URI productivity burden")\nnon_flu_lri_uri_productivity = prod_ests.non_flu_lris_uris*aeorol_rates.non_flu_lris_uris\n\n@name("Covid-19 productivity burden")\ncovid_productivity = (prod_ests.flu+prod_ests.non_flu_lris_uris)*(ylds.covid/(ylds.lris+ylds.uris))*aeorol_rates.covid // sum of other productivity costs * (Covid-19 YLDs/other YLDs) * Covid-19 long range aerosolization rate\n\n@name("Total productivity burden")\nproductivity = flu_productivity+non_flu_lri_uri_productivity+covid_productivity\n\n// Healthcare costs burden\n@name("Influenza healthcare costs burden")\nflu_healthcare = (1.5B to 11.7B)*1.32*aeorol_rates.flu\n\n@name("Non-influenza LRI/URI healthcare costs burden")\nnon_flu_lri_uri_healthcare = (31.2B to 48B)*(17B/40B)*1.76*aeorol_rates.non_flu_lris_uris\n\n@name("Covid-19 healthcare costs burden")\ncovid_healthcare = (137B to 379B)*aeorol_rates.covid\n\n@name("Total healthcare costs burden")\nhealthcare = flu_healthcare+non_flu_lri_uri_healthcare+covid_healthcare\n\n// Total burden\n@name("Total addressable burden of respiratory disease")\ntotal_burden = mortality+illness+productivity+healthcare\n\nTable.make(\n  [ \n    { name: "Mortality burden", value: mortality},\n    { name: "Illness burden", value: illness },\n    { name: "Productivity burden", value: productivity },\n    { name: "Healthcare costs burden", value: healthcare  },\n    { name: "Total addressable burden of respiratory disease", value: total_burden },\n  ],\n  {\n    columns: [\n      { name: "Name", fn: {|d|d.name} },\n      { name: "5th %", fn: {|d|quantile(d.value,5%)} },\n      { name: "Median", fn: {|d|quantile(d.value,50%)} },\n      { name: "Mean", fn: {|d|mean(d.value)} },\n      { name: "95th %", fn: {|d|quantile(d.value,95%)} },\n      { name: "Dist.", fn: {|d|d.value} },\n    ],\n  }\n)\n',
  ],
  [
    "hub:blueprint-biosecurity/endemic-covid-baseline",
    '/*\nDescribe your code here\n*/\n\n// Case rate info\nannual_deaths = 60k to 150k\n//https://covid.cdc.gov/covid-data-tracker/#trends_totaldeaths_select_00 provisional cases in the last year: 65355\n//https://ourworldindata.org/covid-cases confirmed deaths over the last year 1.18m-1.12m = 60000\n//https://www.metaculus.com/questions/7546/deaths-from-covid-19-per-year-2022-2025-in-us/ 130k forecasted per year 2022 to 2025\n\nannual_hospitalisations = 800k to 850k\n//https://covid.cdc.gov/covid-data-tracker/#trends_cumulativehospitalizations_select_00 hospitalisations in the last year: 839988\n// as a sense check https://covid.cdc.gov/covid-data-tracker/#trends_weeklyhospitaladmissions_select_00 over the past year the weekly average is <20k, which matches this\n\nannual_cases = annual_deaths/(0.5 to 1.1)*100 to annual_hospitalisations/(1.1 to 2)*100\n//https://ourworldindata.org/covid-cases case fatality rate over the last year around 1.1% (for confirmed cases and deaths). This is probably an overestimate\n//for flu, 1.1% to 2% of cases lead to hospitalisation. https://www.cdc.gov/flu/about/burden/preliminary-in-season-estimates.htm. Workings https://docs.google.com/spreadsheets/d/1JWC-tObgjzV240o3VP--shWGI2qjUyzEloADOGgrpDM/edit#gid=0\n\nannual_icu = annual_hospitalisations*(15% to 25%)\n// https://covid.cdc.gov/covid-data-tracker/#hospitalizations-severity: 20% of those hospitalised for covid admitted to ICU\n\nlong_term_symptoms = annual_cases*(5% to 15%)\n//arbitrarily adjusting range down from 5-40% to 5-15%, in case the rate has declined as covid has become less severe. Looking into this more would be good\n// https://academic.oup.com/fampra/article/39/1/159/6322429?login=false: 10% to 35% of cases for covid\n//https://www.nature.com/articles/s41467-023-43661-w "The crude prevalence of one or more symptom attributable to SARS-CoV-2 infection was 13.8% (13.2%,14.3%), 12.8% (11.9%,13.6%), and 16.3% (14.4%,18.2%) at 6, 12, and 18 months respectively. Following adjustment for potential confounders, these figures were 6.6% (6.3%, 6.9%), 6.5% (6.0%, 6.9%) and 10.4% (9.1%, 11.6%) respectively." Scotland, % of cases\n//https://www.cdc.gov/nchs/products/databriefs/db480.htm "In 2022, 6.9% of adults ever had Long COVID and 3.4% had Long COVID at the time of interview (currently have Long COVID)" Not obvious how to convert this to % of cases\n//https://www.thelancet.com/journals/eclinm/article/PIIS2589-5370%2822%2900491-6/fulltext "Our work shows that 45% of COVID-19 survivors, regardless of hospitalisation status, were experiencing a range of unresolved symptoms at  4 months. " Global review\n//https://www.cdc.gov/mmwr/volumes/72/wr/mm7232a3.htm "Data from surveys completed between June 113, 2022, and June 719, 2023, indicated that long COVID prevalence decreased from 7.5% (95% CI = 7.17.9) to 6.0% (95% CI = 5.76.3) among the overall U.S. adult population, irrespective of history of previous COVID-19, and from 18.9% (95% CI = 17.919.8) to 11.0% (95% CI = 10.411.6) among U.S. adults reporting previous COVID-19."\n//https://www.cdc.gov/nchs/covid19/pulse/long-covid.htm currently experiencing long covid as % of adults who ever had covid ranges from 9-19%. As % of all adults, from 5-8%\n//https://jamanetwork.com/journals/jama/fullarticle/2805540?guestAccessKey=1fbcad3a-e2ab-492f-8dcc-0288c178fb94&utm_source=For_The_Media&utm_medium=referral&utm_campaign=ftm_links&utm_content=tfl&utm_term=052523 "Among 2231 participants first infected on or after December 1, 2021, and enrolled within 30 days of infection, 224 (10% [95% CI, 8.8%-11%]) were PASC positive at 6 months."\n//https://www.nature.com/articles/s41579-022-00846-2 "Long COVID (sometimes referred to as post-acute sequelae of COVID-19) is a multisystemic condition comprising often severe symptoms that follow a severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection. At least 65 million individuals around the world have long COVID, based on a conservative estimated incidence of 10% of infected people and more than 651 million documented COVID-19 cases worldwide1; the number is likely much higher due to many undocumented cases."\n\n// Valuation info: costs of ill health\nqaly = 250000\n// See https://docs.google.com/document/d/1csvUd9d96D-WmXcO8_jjXn0OjpIB-Xv-7Ne6FKgcL0A/edit\n\nqaly_percent = 0.71 to 0.84\n//https://ifp.org/weighing-the-cost-of-the-pandemic/ For the low estimate, we instead assumed that the people killed had a lower life expectancy (10 years instead of 14.4) and worse health than a typical member of the population in their cohort (an average QALY value of 0.7 instead of 0.81).\n// https://apps.who.int/gho/data/node.main.688: at birth, life expectancy in the US is 78.5 but healthy life expectancy is 66.1 (84%). At 60, this is 23.1/16.4, or 71%\n\nhrqol_sickness = 0.03 to 0.13\n// https://academic.oup.com/cid/article/75/1/e962/6542727 UK nonhospitalised cases. 8.8 QALDS lost for those without symptoms after 6 months. That\'s 0.0241 QALYs over 6 months, which works out at 0.048 HRQOL\n//https://hqlo.biomedcentral.com/articles/10.1186/s12955-024-02230-5 Table 4 HRQOL loss of 0.080 (0.032 to 0.128)\n\nduration_sickness = 7 to 14\n//https://www.hopkinsmedicine.org/health/conditions-and-diseases/coronavirus/diagnosed-with-covid-19-what-to-expect#:~:text=How%20long%20do%20COVID%20symptoms,%2C%20kidneys%2C%20lungs%20and%20brain. "Those with a mild case of COVID-19 usually recover in one to two weeks. "\n\nhealth_cost_sickness = hrqol_sickness*(duration_sickness/365)*qaly\n\nhrqol_hospitalisation = 0.15 to 0.3\n// https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8553121/ "The overall mean HRQoL scores of Acute Covid patients was 60.3 [34] and Long Covid patients ranged from 60.4 to 86.4" Acute range 0.6 to 0.8. See figure 4 for ICU variation\n//https://hqlo.biomedcentral.com/articles/10.1186/s12955-024-02230-5 Table 4 HRQOL loss of 0.15 (0.02 to 0.28)\n\nduration_hospitalisation = 3 to 20\n// https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9472334/: North America estimate 16 days, 95% CI 11 to 20\n// https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7808847/: NorthEastern Ohio for three months in 2019 mean 13.9, SD 9.1, median 12.6 (0.1 to 49.5)\n// https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8259605/: Delaware, 6 months in 2020: "The median LOS was 12.34 days (IQR: 8.68-20.10) and 5.72 days (IQR: 3.40-10.61) for ICU and non-ICU patients, respectively."\n//https://www.medrxiv.org/content/10.1101/2020.04.08.20057794v1.full.pdf: New York, a month in 2020 "Among hospitalized patients, the median length of stay among those with final discharge disposition (discharged alive or died) was 4.8 days (interquartile range, 3.3 to 7.6)"\n//https://link.springer.com/article/10.1007/s12325-021-01887-4: "Overall median hospital LOS, cost, and cost/day were 6 days, US$11,267, and $1772, respectively; overall median ICU LOS, cost, and cost/day were 5 days, $13,443, and $2902, respectively."\n\nhealth_cost_hospitalisation = hrqol_hospitalisation*(duration_hospitalisation/365)*qaly\n\nhrqol_icu = 0.3 to 0.5\n//https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8553121/ "The overall mean HRQoL scores of Acute Covid patients was 60.3 [34] and Long Covid patients ranged from 60.4 to 86.4" ICU range 0.5 to 0.7 HRQol score\n\nduration_icu = 4 to 20\n// https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7808847/: NorthEastern Ohio for three months in 2019 mean 7.4, SD 7.9, median 4.4 (0.1 to 46.9)\n// https://sccm.org/Communications/Critical-Care-Statistics: "ICU LOS has been estimated at 3.8 days in the United States. However, it varies depending on patient and ICU attributes."\n// https://www.sciencedirect.com/science/article/abs/pii/S0964339722000684 US median 6, IQR 3-12\n// https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9040412/ "Over the whole study period, the average length of ICU stays was longer in Ontario (17.2 days) compared to Qubec (12.9 days; p-value <0.01)."\n// https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8259605/: Delaware, 6 months in 2020: "The median LOS was 12.34 days (IQR: 8.68-20.10) and 5.72 days (IQR: 3.40-10.61) for ICU and non-ICU patients, respectively."\n//https://link.springer.com/article/10.1007/s12325-021-01887-4: "Overall median hospital LOS, cost, and cost/day were 6 days, US$11,267, and $1772, respectively; overall median ICU LOS, cost, and cost/day were 5 days, $13,443, and $2902, respectively."\n\nhealth_cost_icu = hrqol_icu*(duration_icu/365)*qaly\n\nhrqol_long_term_symptoms = 0.05 to 0.3\n// https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8553121/ "The overall mean HRQoL scores of Acute Covid patients was 60.3 [34] and Long Covid patients ranged from 60.4 to 86.4"\n//https://hqlo.biomedcentral.com/articles/10.1186/s12955-024-02230-5 Table 4 HRQOL loss of 0.072 (0.042 to 0.103). For mild to moderate Covid cases. "In the survey, long COVID was defined according to the National Institute for Health and Care Excellence (NICE) as symptoms which cannot be explained by an alternative diagnosis or condition and which lasted or developed 12 weeks beyond the initial COVID-19 infection"\n// https://academic.oup.com/cid/article/75/1/e962/6542727 cases with symptoms at 6 months: 32.8 QALDs lost (24.2 to 37.6 95 CI). Over 6 months, that\'s 0.18 HRQOL (0.13 to 0.2)\n\nduration_long_term_symptoms = 56 to 365\n// https://raeng.org.uk/media/fupdixju/nera-social-cost-benefit-analysis.pdf 1 year. "we take a higher HRQoL to account for uncertainty (although is it not yet fully known and studies generally estimate HRQoL between 4-12 weeks)." In the spreadsheet\n//https://www.covid.gov/be-informed/longcovid/about#term "Long COVID is a patient created term broadly defined as signs, symptoms, and conditions that continue or develop after initial SARS-CoV-2 infection. The signs, symptoms, and conditions are present four weeks or more after the initial phase of infection"\n\nhealth_cost_long_term_illness = hrqol_long_term_symptoms*(duration_long_term_symptoms/365)*qaly\n\naverage_yll = 8 to 17\n//https://bmcpublichealth.biomedcentral.com/articles/10.1186/s12889-021-12377-1/figures/1: 8\n//https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8877807/: 31.45 YLL per 1000 people, 1.84 deaths per 1000 people, so 17\n//https://www.nature.com/articles/s41598-021-83040-3#data-availability we could get this info from their data if we tried\n//https://www.pewresearch.org/short-reads/2021/06/16/americans-lost-more-years-of-life-to-covid-19-in-2020-than-to-all-accidents-combined-in-a-typical-year/"In 2020 alone, the coronavirus was responsible for about 380,000 deaths and roughly 5.5 million years of lost life in the United States, according to a Pew Research Center analysis of provisional data from the Centers for Disease Control and Prevention." 5500000/380000 is 14.5\n//https://raeng.org.uk/media/fupdixju/nera-social-cost-benefit-analysis.pdf 11-15 YLL\n\n// Sense check with endemic flu model by converting hrqols into QALY loss\nqaly_loss_sickness = hrqol_sickness*(duration_sickness/365)\nqaly_loss_hospitalisation = hrqol_hospitalisation*duration_hospitalisation/365\nqaly_loss_icu = hrqol_icu*duration_icu/365\n\n// Valuation info: costs of healthcare\nhospital_bed = 2000 to 3000\n//estimated based on 2022 CA OSHPD data\n//https://www.statista.com/statistics/630443/inpatient-day-hospital-costs-in-us-by-nonprofit-or-profit/#:~:text=In%202021%2C%20the%20average%20cost,at%20a%20for%2Dprofit%20hospital.: "In 2021, the average cost of an inpatient day at non-profit hospitals was 3,013 dollars, compared to 2,296 dollars at a for-profit hospital."\n//https://link.springer.com/article/10.1007/s12325-021-01887-4: "Overall median hospital LOS, cost, and cost/day were 6 days, US$11,267, and $1772, respectively; overall median ICU LOS, cost, and cost/day were 5 days, $13,443, and $2902, respectively."\n\ncost_hospitalisation = hospital_bed*duration_hospitalisation\n\nicu_bed = 2500 to 3500\n//estimated based on 2022 CA OSHPD data\n//https://link.springer.com/article/10.1007/s12325-021-01887-4: "Overall median hospital LOS, cost, and cost/day were 6 days, US$11,267, and $1772, respectively; overall median ICU LOS, cost, and cost/day were 5 days, $13,443, and $2902, respectively."\n//https://www.atsjournals.org/doi/10.1513/AnnalsATS.201506-366BC 2015, around $2000 per day in different kinds of ICU\n\ncost_icu_hospitalisation = icu_bed*duration_icu\n\n//Expected costs of ill health\nsickness_costs = health_cost_sickness*(annual_cases-annual_hospitalisations-long_term_symptoms)\nhospitalisation_costs = health_cost_hospitalisation*(annual_hospitalisations-annual_icu)\nicu_costs = health_cost_icu*(annual_icu)\nviv_check = sickness_costs + hospitalisation_costs + icu_costs\ndeath_costs = average_yll*annual_deaths*qaly*qaly_percent\nlong_term_symptoms_costs = health_cost_long_term_illness*long_term_symptoms\ntotal_expected_costs_ill_health = sickness_costs+hospitalisation_costs+icu_costs+death_costs+long_term_symptoms_costs\npercent_sickness = sickness_costs/total_expected_costs_ill_health\npercent_hospitalisation = hospitalisation_costs/total_expected_costs_ill_health\npercent_icu = icu_costs/total_expected_costs_ill_health\npercent_death = death_costs/total_expected_costs_ill_health\npercent_long_term_symptoms = long_term_symptoms_costs/total_expected_costs_ill_health\nqaly_sickness = hrqol_sickness*(duration_sickness/365)*(annual_cases-annual_hospitalisations-long_term_symptoms)\nqaly_hospitalisation = hrqol_hospitalisation*(duration_hospitalisation/365)*(annual_hospitalisations-annual_icu)\nqaly_icu = hrqol_icu*(duration_icu/365)*(annual_icu)\nqaly_death = annual_deaths*average_yll*qaly_percent\nqaly_long_term_symptoms = hrqol_long_term_symptoms*(duration_long_term_symptoms/365)*long_term_symptoms\ntotal_qaly_costs = qaly_sickness+qaly_hospitalisation+qaly_icu+qaly_death+qaly_long_term_symptoms\n\n//Expected healthcare costs\nhospitalisation_healthcare_costs = cost_hospitalisation*annual_hospitalisations\nicu_healthcare_costs = cost_icu_hospitalisation*annual_icu\ntotal_expected_costs_heatlhcare = hospitalisation_healthcare_costs+icu_healthcare_costs\n\n// Total expected annual costs\ntotal_expected_costs = total_expected_costs_heatlhcare+total_expected_costs_ill_health\n',
  ],
  [
    "hub:blueprint-biosecurity/far-uvc-botec",
    '// Context here: https://docs.google.com/document/d/119_ADMYWSBdzAdqXMuKepphpQqZxSY7yU7DDCYjD-sY/edit\n\n//Switches\nextinction_off = 1//0 is off, 1 is on\nnon_exctinction_off = 1 //0 is off, 1 is on\n\n//Risk reduction\npathogen_inactivation = {\n  k = 0.01 to 15 // a bit wider than the range here https://docs.google.com/spreadsheets/d/1lVr0aWTFvlcjG2Rp7GPKOan_ET2hwSBoy05Ap8KsUko/edit#gid=0\nfluence = 1 to 20 // 5 is current eye TLV. 20 is a guess. This is where I\'d look for more: https://docs.google.com/spreadsheets/d/1MloCPdN72vSGUxUUeDeeqdW4b1wAT5RIRJW1AVl-AaI/edit#gid=0\nbase_ACH = 1 to 15 // 1DS IAQ report: ASHRAE standards "approximately 1-2 ACH in residences and offices (though half of studied buildings fall below ASHRAE standards)." "high levels of eACH up to CDC hospital standards (8-12 eACH)". Assuming that base ACH might be much higher in a pandemic\nbase_decay = 0.1 to 0.3 // no idea, these were the dummy numbers Richard used here https://docs.google.com/spreadsheets/d/1oOwXuZvLjiqf3zGoF7a2hKLv_3-ZZiISdTZ07RpsQIA/edit#gid=0\n  1-(base_ACH+base_decay)/(base_ACH+base_decay+(k*fluence*3.6))\n}\n\nrisk_reduction_data = {\n  deployment_rate: 20% to 60%,\n  percent_aerosolised: 5% to 50%\n}\n\nrisk_reduction = pathogen_inactivation*risk_reduction_data.deployment_rate*risk_reduction_data.percent_aerosolised\n\n//Baseline\npandemic_data = {\n  pop: 8B,\n  pandemic_duration: 2 to 4,\n  x_risk_death_weighting: 1 to 100, // XPT supers imply 63 lives for every person alive now (13-503 25th-75th). p. 345. But they estimate much lower x risk\n economic_multiplier: 2 to 100, // I think GWH uses 2 as a rule of thumb for non-existential pandemics. Seems like it could be a lot higher with civilizational collapse\n  annual_bio_x_risk: (0.1% to 10%)/30, // BPP: 0.1% to 10% over 30 years. XPT supers post XPT imply (0.01%+0.0018%)/(2100-2020) = 0.0001%. Ord implies (1/30)/100 = 0.03%. Could also add a factor by which this increases over time, but that would presumbaly be swamped by x risk increasing over time.\n  daly: 100k // I think this is OP\'s number\n}\n\nannual_extinction_baseline = {\n  severity = 100%\n  annual_expected_deaths = pandemic_data.pop*severity*pandemic_data.annual_bio_x_risk*pandemic_data.x_risk_death_weighting/pandemic_data.pandemic_duration\n  avg_yll = 40 to 70\n  expected_yll = annual_expected_deaths*avg_yll\n  expected_yll*pandemic_data.daly\n  }\n\nannual_catastrophe_baseline = {\n  severity = 10% to 99%\n  annual_p = (3%+0.85%)/(2100-2020) // XPT supers after XPT: 0.08%+1%. XPT domain experts: 3%+0.85%. https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/64f0a7838ccbf43b6b5ee40c/1693493128111/XPT.pdf, p. 66.\n  annual_expected_deaths = pandemic_data.pop*severity*annual_p*pandemic_data.economic_multiplier/pandemic_data.pandemic_duration\n  avg_yll = 10 to 40\n  expected_yll = annual_expected_deaths*avg_yll\n  expected_yll*pandemic_data.daly\n  }\n  \nannual_Spanish_flu_baseline = {\n  severity = 3%\n  annual_p = 0.02% to 0.89% // "https://www.pnas.org/doi/epdf/10.1073/pnas.2105482118: Spanish flu exceedance 0.11%-0.89% from 1600 to present. https://pubmed.ncbi.nlm.nih.gov/30212163/: \'The annual probability of an influenza pandemics meeting or exceeding the global mortality rate of the 1918 Spanish flu pandemic (111555 deaths per 10,000 persons) is less than 0.02 percent."\n  annual_expected_deaths = pandemic_data.pop*severity*annual_p*pandemic_data.economic_multiplier/pandemic_data.pandemic_duration\n  avg_yll = 10 to 20\n  expected_yll = annual_expected_deaths*avg_yll\n  expected_yll*pandemic_data.daly\n  }\n\nannual_endemic_baseline = {\n  expected_yll = 125M to 159M //https://vizhub.healthdata.org/gbd-results/?params=gbd-api-2019-permalink/f05fb4c2c2eff1b51312420333435c4e\n  expected_yll*pandemic_data.daly\n  }\n\nundiscounted_baseline = annual_extinction_baseline*extinction_off+annual_catastrophe_baseline*non_exctinction_off+annual_Spanish_flu_baseline*non_exctinction_off+annual_endemic_baseline*non_exctinction_off\n\nannual_baseline_breakdown = {\n  extinction: annual_extinction_baseline/undiscounted_baseline,\n  catastrophe: annual_catastrophe_baseline/undiscounted_baseline,\n  spanish_flu: annual_Spanish_flu_baseline/undiscounted_baseline,\n  endemic: annual_endemic_baseline/undiscounted_baseline\n}\n\n//Discounting\ndiscount_rate = {\n  annual_x_risk = 0.13% // Ord implies (1/6-1/30))/100 = 0.13%\n  annual_p_TAI = 1.25% // Karnosky implies 50%/(2060-2020) = 1.25%\n  annual_x_risk+annual_p_TAI // this is an overestimate as there\'s overlap between x risk and TAI\n}\n\nyears_to_point_x = 10 to 100\nprobability_point_x = 30% to 70% // probability far-UVC ever reaches point x\n\ndiscounted_baseline = undiscounted_baseline*(1+discount_rate)^-years_to_point_x\n\n// Results\nwtp_one_year_speedup = (discounted_baseline*risk_reduction*probability_point_x)/2000\n\ncosts = 10M // this is just a placeholder for a grant amount\n\nspeedup_required = (2000*costs)/(discounted_baseline*risk_reduction*probability_point_x)\n\nspeedup = 0.5 to 5 // this is just a placeholder for an estimated speedup from a grant\n\nbcr = (risk_reduction*discounted_baseline*speedup*probability_point_x)/(costs)',
  ],
  [
    "hub:blueprint-biosecurity/DALY-x-risk-BOTEC",
    "/*\nDescribe your code here\n*/\n\n//Risk reduction\nrisk_reduction = 1% // placeholder\n\n//Baseline\npandemic_data = {\n  pop: 8B,\n  pandemic_duration: 2 to 4,\n  x_risk_death_weighting: 1 to 100, // XPT supers imply 63 lives for every person alive now (13-503 25th-75th). p. 345. But they estimate much lower x risk\n  annual_bio_x_risk: (0.1% to 10%)/30, // BPP: 0.1% to 10% over 30 years. Could also add a factor by which this increases over time, but that would presumbaly be swamped by x risk increasing over time.\n  daly: 100k // I think this is OP's number\n}\n\nannual_baseline = {\n  severity = 100%\n  annual_expected_deaths = pandemic_data.pop*severity*pandemic_data.annual_bio_x_risk*pandemic_data.x_risk_death_weighting/pandemic_data.pandemic_duration\n  avg_yll = 40 to 70 // average age worldwide is 30. average life expectancy worldwide is 70. \n  expected_yll = annual_expected_deaths*avg_yll\n  expected_yll*pandemic_data.daly\n  }\n\n//Discounting\ndiscount_rate = {\n  annual_x_risk = 0.13% // Ord implies (1/6-1/30))/100 = 0.13%\n  annual_p_TAI = 1.25% // Karnosky implies 50%/(2060-2020) = 1.25%\n  annual_x_risk+annual_p_TAI // this is an overestimate as there's overlap between x risk and TAI\n}\n\ncounterfactual_probability = 1% to 10% // probability far-UVC reaches maturity\ncounterfactual_years_in_future = 10 to 100 // number of years to maturity conditional on it happening\nspeedup = 1 // placeholder\n\ndiscounted_baseline = annual_baseline*(1+discount_rate)^-(counterfactual_years_in_future-speedup)\n\n// Benefits\nbenefit = discounted_baseline*counterfactual_probability*speedup*risk_reduction\n\n//WTP\nwtp = benefit/2000",
  ],
  [
    "hub:mdickens/Uganda-Community-Farm-sorghum",
    "/*\n * Cost-effectiveness analysis for Uganda Community Farm's program to \n * buy sorghum seeds and supplies necessary to grow sorghum.\n * \n * Some parts of this model are copy/pasted from\n * https://squigglehub.org/models/mdickens/Uganda-Community-Farm-facility \n */\n\n// As of 2024-05-24\nugx_to_usd = 1 / 3828\nhectares_to_acres = 2.471\ntonnes_to_kg = 1000\n\n// Coefficient of relative risk aversion. Higher = more risk averse. A coefficient of 1 corresponds to logarithmic utility of money, which is consistent with GiveWell's models.\nrisk_aversion_coefficient = 1\n\n// Cost to grow crops. From Anthony's Q&A post, with correction on spray pump cost (per season instead of per year)\ninput_cost_per_acre_per_season_usd = 6.8 + 10 + 2.5 + 8\n\n// Based on prices 20192024 according to Anthony, which is consistent with projected 2024 market price according to ReliefWeb:\n// https://reliefweb.int/report/uganda/uganda-wfp-vam-food-security-analysis-national-market-monitor-report-march-2024\nsorghum_price_per_kg_ugx = normal({ p25: 1050, p75: 1500 })\n\n// Number taken from Anthony's post. Roughly consistent with\n// https://ourworldindata.org/grapher/sorghum-yield?tab=chart&country=~UGA\n// Anthony's number is somewhat higher than OWID's number (700 kg/acre = 1.7 tonnes/hectare) but I'll use his number to be generous\nsorghum_harvest_kg_per_acre = normal(700, 100)\nsorghum_harvests_per_year = 2\n\n// Sugarcane has a yield ~60x higher than sorghum, idk how that works but it's what OWID says. And it's consistent with the fact that sorghum is way more expensive\n// https://ourworldindata.org/grapher/sugar-cane-yields?tab=chart&country=~UGA\nsugarcane_yield_kg_per_hectare_national_average = normal(70, 2) * tonnes_to_kg\n\n// Farmers near UCF probably have worse yields than the national average\nsugarcane_inefficient_farming_multiplier = normal({ p25: 0.8, p75: 0.9 })\n\n// According to Anthony, sugarcane takes 2 years to grow\nsugarcane_harvests_per_year = 0.5\n\n// Sugarcane price is very volatile\n// https://www.monitor.co.ug/uganda/news/national/sugarcane-prices-drop-by-shs110-000-in-busoga-4631166\nsugarcane_price_per_kg_ugx = normal({ p10: 96, p90: 240 })\n\n// Anthony wrote as if 1 farmer = 1 acre, which implies an income that's roughly consistent with poverty level in region.\n// Uganda Bureau of Stats reports avg 1.3 hectares per farmer, with 67% having less than 1 hectare:\n// https://www.ubos.org/wp-content/uploads/publications/05_2022Uganda_UBOS_StatRelease_AAS2019-Final.pdf\n// I'm assuming the farmers in Kamuli & Buyende mostly have smaller farms than that.\nhectares_per_farmer = lognormal({ p25: 0.5, p75: 1 })\n\n/* \n * Calculations\n */\n\nsorghum_cost_per_acre_per_year_usd = input_cost_per_acre_per_season_usd * sorghum_harvests_per_year\n\nacres_per_farmer = hectares_per_farmer * hectares_to_acres\nsugarcane_yield_kg_per_hectare = sugarcane_yield_kg_per_hectare_national_average *\n  sugarcane_inefficient_farming_multiplier\n\nsugarcane_yield_kg_per_acre_per_year = sugarcane_yield_kg_per_hectare /\n  hectares_to_acres *\n  sugarcane_harvests_per_year\nsorghum_yield_kg_per_acre_per_year = sorghum_harvest_kg_per_acre *\n  sorghum_harvests_per_year\n\nsugarcane_revenue_per_acre_per_year_usd = sugarcane_yield_kg_per_acre_per_year *\n  sugarcane_price_per_kg_ugx *\n  ugx_to_usd\nsorghum_revenue_per_acre_per_year_usd = sorghum_yield_kg_per_acre_per_year *\n  sorghum_price_per_kg_ugx *\n  ugx_to_usd\n\nsugarcane_revenue_per_year_usd = sugarcane_revenue_per_acre_per_year_usd *\n  acres_per_farmer\nsorghum_revenue_per_year_usd = sorghum_revenue_per_acre_per_year_usd *\n  acres_per_farmer\n\n// Certainty-equivalent revenue is the amount of guaranteed revenue you'd accept instead of your current risky revenue. The riskier your actual revenue stream, the less it's worth.\n// This calculation uses an approximation to account for risk aversion. This approximation is commonly used for stock returns but idk if it's applicable here. Intuitively, it looks like this doesn't penalize risk enough, but maybe my intuition is wrong.\nsugarcane_certainty_equivalent_revenue = sugarcane_revenue_per_year_usd -\n  risk_aversion_coefficient * Dist.variance(sugarcane_revenue_per_year_usd) /\n    sugarcane_revenue_per_year_usd /\n    2\nsorghum_certainty_equivalent_revenue = sorghum_revenue_per_year_usd -\n  risk_aversion_coefficient * Dist.variance(sorghum_revenue_per_year_usd) /\n    sorghum_revenue_per_year_usd /\n    2\n\n// Technically shouldn't truncate, but a tiny part of the dist is below 0 which means we can't calculate the logarithm without truncating\nold_income = Dist.truncateLeft(sugarcane_certainty_equivalent_revenue, 0)\nnew_income = Dist.truncateLeft(sorghum_certainty_equivalent_revenue, 0)\n\n// logc is short for log(consumption)\nlogc_units_per_farmer_per_year = Dist.log(new_income) - Dist.log(old_income)\n\nlogc_units_per_dollar = logc_units_per_farmer_per_year /\n  sorghum_cost_per_acre_per_year_usd\n\n// From GiveWell CEA: https://docs.google.com/spreadsheets/d/18ROI6dRdKsNfXg5gIyBa1_7eYOjowfbw5n65zkrLnvc/edit#gid=\ngivedirectly_logc_units_per_dollar = 238 / 100000\n\n/* \n * Model Results\n */\n\ncost_effectiveness_vs_givedirectly = logc_units_per_dollar /\n  givedirectly_logc_units_per_dollar\n",
  ],
  [
    "hub:mlao-pdx/stringSort",
    'import "hub:mlao-pdx/lib-common" as c\n/* \nA quick and dirty hack to merge sort a list of basic strings.\n\nRelatively easy to strip and reuse for other sorting needs. \n\nI\'ll come back later to clean-up and document.\n*/\n\nmaxLength(lists) = lists\n  -> map(\n    {\n      |list|\n      List.length(\n        typeOf(list) == "String" ? String.split(list, "") : c.listIt(list)\n      )\n    }\n  )\n  -> max\n\npadUpTo(list, length, value) = List.slice(\n  concat(list, List(length, value)),\n  0,\n  length\n)\n\nmerge(left, right, comparison) = {\n  /* Make sure paddingValue falls outside of any reaonable collationSequence length */\n  paddingValue = 9P\n  /* Make sure that each side ends in one or more padding values \n  to ensure unequal length lists are BOTH fully processed. */\n  padLength = maxLength([left, right]) + 1\n  left = left\n    -> padUpTo(\n      padLength,\n      { sort: List(List.length(left[0].sort), paddingValue) }\n    )\n  right = right\n    -> padUpTo(\n      padLength,\n      { sort: List(List.length(right[0].sort), paddingValue) }\n    )\n\n  result = List.reduceWhile(\n    List(padLength * 2, {|_| _}),\n    { li: 0, ri: 0, sl: [] },\n    {\n      |acc, _|\n      comparison(left[acc.li], right[acc.ri]) ? {\n        li: acc.li + 1,\n        ri: acc.ri,\n        sl: left[acc.li] != paddingValue ? List.append(\n          acc.sl,\n          left[acc.li]\n        ) : acc.sl,\n      } : {\n        li: acc.li,\n        ri: acc.ri + 1,\n        sl: right[acc.ri] != paddingValue ? List.append(\n          acc.sl,\n          right[acc.ri]\n        ) : acc.sl,\n      }\n    },\n    {|acc| acc.li < padLength && acc.ri < padLength}\n  )\n\n  result.sl\n}\n\nmergeSort(list, comparison, tail) = if List.length(list) <= 1 then list else {\n  mid = floor(List.length(list) / 2)\n  left = tail(List.slice(list, 0, mid), comparison, tail)\n  right = tail(List.slice(list, mid, List.length(list)), comparison, tail)\n  merge(left, right, comparison)\n}\n\nindexString(value, collationIndices, undeterminedIndex) = String.split(\n  value,\n  ""\n)\n  -> map(\n    {\n      |char|\n      index = List.findIndex(collationIndices, {|position| position == char})\n      index == -1 ? undeterminedIndex : index\n    }\n  )\n\n@doc("<0 left is smaller, 0 equal, >0 right is smaller")\ncompareStringIndices(x, y) = {\n  length = max(List.length(x.sort), List.length(y.sort))\n  List.zip(padUpTo(x.sort, length, 0), padUpTo(y.sort, length, 0))\n    -> reduce(\n      0,\n      {|result, item| result == 0 ? item[0] - item[1] : result}\n    )\n}\n\n@doc("Python string.printable.")\n@name("A string with the characters in default sorting order")\nexport defaultCollation = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\\"#$%&\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r"\n\n@doc(\n  "Sort a list of strings. \n\n- **list**: A list of strings, where any non-string will be converted into a string.\n- **function**: An inline function that allows sorting to happen on a derivation of the list item.\nDefaults to the item itself when \\"\\" is passed as its value.\n- **collationSequence**: A string with the characters in desired sorting order. \nDefaults to Python\'s string.printable when \\"\\" passed as its value.\n"\n)\n@name("stringSort(list, function, collationSequence) => List")\nexport stringSort(list, function, collationSequence) = {\n  collationSequence = collationSequence ==\n    "" ? defaultCollation : collationSequence\n  collationIndices = String.split(concat("", collationSequence), "")\n  undeterminedIndex = List.length(collationIndices) + 1\n  function = function == "" ? {|_| _} : function\n\n  maxStringLength = maxLength(list)\n  list = list\n    -> map(\n      {\n        |_|\n        {\n          text: _,\n          sort: indexString(\n            typeOf(function(_)) != "String" ? String(function(_)) : function(_),\n            collationIndices,\n            undeterminedIndex\n          ),\n        }\n      }\n    )\n\n  comparison = {|l, r| compareStringIndices(l, r) < 0}\n  mergeSort(list, comparison, mergeSort) -> map({|_| _.text})\n}\n\nCalculator(\n  stringSort,\n  {\n    inputs: [\n      Input.text(\n        {\n          name: "list",\n          default: "[ [1, \\"Foobar\\"], [2, \\"Bar\\"], [3, \\"Foo\\"] ]",\n        }\n      ),\n      Input.text({ name: "function", default: "{|_| _[1]}" }),\n      Input.text({ name: "collationSequence", default: "\\"\\"" }),\n    ],\n  }\n)',
  ],
  [
    "hub:patbl/water-filtration-system-comparison",
    'Calculator.make({|resident_count, liters_per_day_per_resident, filtered_fraction, home_fraction, tap_gpm, apec_gpm, multipure_gpm, culligan_gpm|\n  annual_hours_spent_dispensing_water(gpm) = {\n    liters_per_gallon = 128/33.8\n    gallons_per_day_per_resident = liters_per_day_per_resident / liters_per_gallon\n    filtered_at_home_gallons_per_day_per_resident =\n      gallons_per_day_per_resident * home_fraction * filtered_fraction\n    filtered_gallons_dispensed_at_home_per_year = resident_count *\n      filtered_at_home_gallons_per_day_per_resident *\n      365.25\n    filtered_gallons_dispensed_at_home_per_year / gpm / 60\n  }\n  annual_hours_tap = annual_hours_spent_dispensing_water(tap_gpm)\n  \n  annual_hours_apec_reverse_osmosis = annual_hours_spent_dispensing_water(apec_gpm)\n  annual_hours_multipure = annual_hours_spent_dispensing_water(multipure_gpm)\n  annual_hours_culligan = annual_hours_spent_dispensing_water(culligan_gpm)\n\n  Table.make(\n  [\n    { name: "none", value: annual_hours_tap },\n    { name: "APEC ROES-PH75", value: annual_hours_apec_reverse_osmosis },\n    { name: "Multipure Aquaversa", value: annual_hours_multipure },\n    { name: "Culligan US-EZ-4", value: annual_hours_culligan },\n  ],\n  {\n    columns: [\n      { name: "filter type", fn: {|d| d.name } },\n      { name: "annual hours", fn: {|d| round(mean(d.value)) } },\n      { name: "extra hours compared to tap", fn: {|d| round(mean(d.value - annual_hours_tap)) }},\n      { name: "Dist", fn: {|d|d.value} },\n    ],\n  }\n)\n}, {\n  title: "annual at-home filtered-water consumption",\n  inputs: [\n    Input.text({ name: "number of residents", default: "12" }),\n    Input.text({ name: "liters of drinking water consumed per day per resident", default: "1 to 2.5" }),\n        Input.text({ name: "fraction of drunk water consumed at home (as opposed to at work, during travel, etc.)", default: "0.5 to 0.8"}),\n    Input.text({ name: "fraction of water drunk at home that\'s filtered", default: "0.4 to 0.9"}),\n    Input.text({\n      name: "gallons per minute from tap",\n      default: "1.2 to 1.7",\n      description: "I measured this. The downstairs kitchen faucet is about 1.3 gallons/minute; the upstairs one is more like 1.6 gallons/minute.",\n    }),\n    Input.text({\n      name: "gallons per minute from APEC ROES-PH75 (reverse osmosis)",\n      default: "0.25 to 0.5",\n      description: "No claim is made in the official product description. At https://www.amazon.com/ask/questions/Tx36UWEEXJ1H4UZ, the manufacturer claims a 0.5 GPM flow rate \\"when the storage tank is full.\\" (For what it\'s worth, a customer also responded saying that it takes about fifteen minutes to dispense a gallon.) I discounted the manufacturer\'s claim because (1) Various sources claim that reverse-osmosis systems are slow; (2) The claim was made in a response to a question from a customer on Amazon, not in an official specification; and (3) The Kinetico RO system costs $2k+ and claims 0.5 GPM. It makes a big deal of how fast it is (it\'s even in the name). I would expect a budget system to be slower.",\n    }),\n    Input.text({\n      name: "gallons per minute from Multipure Aquaversa",\n      default: "(0.75 * 0.8) to 0.75",\n      description: "The manufacturer claims 0.75 GPM on its website. Consumer Reports gave it 5/5 for flow rate.",\n    }),\n    Input.text({\n      name: "gallons per minute from Culligan US-EZ-4",\n      default: "(0.5 * 0.8) to 0.5",\n      description: "The manufacturer claims 0.5 GPM on its website. Consumer Reports gave it 4/5 for flow rate.\n",\n    }),\n  ],\n  sampleCount: 10k,\n})\n\n',
  ],
]);
